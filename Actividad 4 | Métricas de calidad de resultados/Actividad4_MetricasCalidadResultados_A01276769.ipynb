{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c667fc",
   "metadata": {},
   "source": [
    "# Actividad 4 | M茅tricas de calidad de resultados\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2888f4",
   "metadata": {},
   "source": [
    "**MAESTRA EN INTELIGENCIA ARTIFICIAL APLICADA**\n",
    "\n",
    "**Curso: TC4034.10 - An谩lisis de grandes vol煤menes de datos**\n",
    "\n",
    "Tecnol贸gico de Monterrey\n",
    "\n",
    "* Dr. Iv谩n Olmos Pineda\n",
    "* Mtra. Ver贸nica Sandra Guzm谩n de Valle\n",
    "* Mtro. Alberto Daniel Salinas Montemayor\n",
    "\n",
    "**Actividad 4** - \n",
    "M茅tricas de calidad de resultados\n",
    "\n",
    "**Fecha de entrega** - \n",
    "8 de junio del 2025\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c4a7c",
   "metadata": {},
   "source": [
    "**Presenta**\n",
    "\n",
    "|  NOMBRE COMPLETO                        |     MATRCULA     |\n",
    "| :-------------------------------------: |:-----------------:|\n",
    "| Alejandro D铆az Villag贸mez               |  A01276769        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62f588",
   "metadata": {},
   "source": [
    "# 0) Carga de datos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3760e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/alejandrodiazvillagomez/Desktop/Proyecto-Big-Data-PySpark/.venv/lib/python3.12/site-packages/pyspark'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from itertools import product\n",
    "from os import path\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "492e017b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/01 20:07:43 WARN Utils: Your hostname, Alejandros-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.100.202 instead (on interface en0)\n",
      "25/06/01 20:07:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/01 20:07:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.100.202:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x105fccdd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a140f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileManager():\n",
    "    @staticmethod\n",
    "    def open_csv_file(file_path : str):\n",
    "        \"\"\"\n",
    "        This method opens a csv file with pyspark\n",
    "        \"\"\"\n",
    "        csv_df = spark.read.csv(\n",
    "            file_path,\n",
    "            header=True,\n",
    "            inferSchema=True,\n",
    "            multiLine=True,\n",
    "            escape=\"\\\"\",\n",
    "            quote=\"\\\"\"\n",
    "        )\n",
    "\n",
    "        # csv_df.show(truncate=20)\n",
    "\n",
    "        return csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eedc112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandrodiazvillagomez/Desktop/Proyecto-Big-Data-PySpark/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/alejandrodiazvillagomez/.cache/kagglehub/datasets/machharavikiran/amazon-reviews/versions/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>22873041</td>\n",
       "      <td>R3ARRMDEGED8RD</td>\n",
       "      <td>B00KJWQIIC</td>\n",
       "      <td>335625766</td>\n",
       "      <td>Plemo 14-Inch Laptop Sleeve Case Waterproof Fa...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Pleasantly surprised</td>\n",
       "      <td>I was very surprised at the high quality of th...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>30088427</td>\n",
       "      <td>RQ28TSA020Y6J</td>\n",
       "      <td>B013ALA9LA</td>\n",
       "      <td>671157305</td>\n",
       "      <td>TP-Link OnHub AC1900 Wireless Wi-Fi Router</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>OnHub is a pretty no nonsense type router that...</td>\n",
       "      <td>I am a Google employee and had to chance to us...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>20329786</td>\n",
       "      <td>RUXJRZCT6953M</td>\n",
       "      <td>B00PML2GQ8</td>\n",
       "      <td>982036237</td>\n",
       "      <td>AmazonBasics USB 3.0 A Male to A Male Cable - ...</td>\n",
       "      <td>PC</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>None of them worked.  No functionality at all.</td>\n",
       "      <td>Bought cables in 3ft, 6ft and 9ft.  NONE of th...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>14215710</td>\n",
       "      <td>R7EO0UO6BPB71</td>\n",
       "      <td>B001NS0OZ4</td>\n",
       "      <td>576587596</td>\n",
       "      <td>Transcend P8 15-in-1 USB 2.0 Flash Memory Card...</td>\n",
       "      <td>PC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>just keep searching.</td>\n",
       "      <td>nope, cheap and slow</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>38264512</td>\n",
       "      <td>R39NJY2YJ1JFSV</td>\n",
       "      <td>B00AQMTND2</td>\n",
       "      <td>964759214</td>\n",
       "      <td>Aleratec SATA Data Cable 2.0 20in Serial ATA S...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Excellent! Great value and does the job.</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US</td>\n",
       "      <td>30548466</td>\n",
       "      <td>R31SR7REWNX7CF</td>\n",
       "      <td>B00KX4TORI</td>\n",
       "      <td>170101802</td>\n",
       "      <td>Kingston Digital MobileLite G4 USB 3.0 Multi-F...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Good quality, works well and compact</td>\n",
       "      <td>Good quality,works well and compact size</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>US</td>\n",
       "      <td>589298</td>\n",
       "      <td>RVBP8I1R0CTZ8</td>\n",
       "      <td>B00P17WEMY</td>\n",
       "      <td>206124740</td>\n",
       "      <td>White 9 Inch Unlocked Dual Sim Card Phone Tabl...</td>\n",
       "      <td>PC</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>in fact this is third China good. Demn s***</td>\n",
       "      <td>This demn tablet is just a Real Chinese produc...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>US</td>\n",
       "      <td>49329488</td>\n",
       "      <td>R1QF6RS1PDLU18</td>\n",
       "      <td>B00TR05L9Y</td>\n",
       "      <td>778403103</td>\n",
       "      <td>Lenovo TAB2 A10 - 10.1\" 2-in-1 Tablet (1.5Ghz,...</td>\n",
       "      <td>PC</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Good</td>\n",
       "      <td>I am not sure I don't know if it is the tablet...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>US</td>\n",
       "      <td>50728290</td>\n",
       "      <td>R23AICGEDAJQL1</td>\n",
       "      <td>B0098Y77OG</td>\n",
       "      <td>177098042</td>\n",
       "      <td>Acer</td>\n",
       "      <td>PC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>You get what you pay for</td>\n",
       "      <td>After exactly 45 days, the screen went dark. P...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>US</td>\n",
       "      <td>37802374</td>\n",
       "      <td>R2EY3N4K9W19UP</td>\n",
       "      <td>B00IFYEYXC</td>\n",
       "      <td>602496520</td>\n",
       "      <td>AzureWave Broadcom BCM94352HMB 802.11/ac/867Mb...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great for Windows 7 Laptop!</td>\n",
       "      <td>Replaced my Intel Centrino 2230 with the BCM94...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     22873041  R3ARRMDEGED8RD  B00KJWQIIC       335625766   \n",
       "1          US     30088427   RQ28TSA020Y6J  B013ALA9LA       671157305   \n",
       "2          US     20329786   RUXJRZCT6953M  B00PML2GQ8       982036237   \n",
       "3          US     14215710   R7EO0UO6BPB71  B001NS0OZ4       576587596   \n",
       "4          US     38264512  R39NJY2YJ1JFSV  B00AQMTND2       964759214   \n",
       "5          US     30548466  R31SR7REWNX7CF  B00KX4TORI       170101802   \n",
       "6          US       589298   RVBP8I1R0CTZ8  B00P17WEMY       206124740   \n",
       "7          US     49329488  R1QF6RS1PDLU18  B00TR05L9Y       778403103   \n",
       "8          US     50728290  R23AICGEDAJQL1  B0098Y77OG       177098042   \n",
       "9          US     37802374  R2EY3N4K9W19UP  B00IFYEYXC       602496520   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  Plemo 14-Inch Laptop Sleeve Case Waterproof Fa...               PC   \n",
       "1         TP-Link OnHub AC1900 Wireless Wi-Fi Router               PC   \n",
       "2  AmazonBasics USB 3.0 A Male to A Male Cable - ...               PC   \n",
       "3  Transcend P8 15-in-1 USB 2.0 Flash Memory Card...               PC   \n",
       "4  Aleratec SATA Data Cable 2.0 20in Serial ATA S...               PC   \n",
       "5  Kingston Digital MobileLite G4 USB 3.0 Multi-F...               PC   \n",
       "6  White 9 Inch Unlocked Dual Sim Card Phone Tabl...               PC   \n",
       "7  Lenovo TAB2 A10 - 10.1\" 2-in-1 Tablet (1.5Ghz,...               PC   \n",
       "8                                               Acer               PC   \n",
       "9  AzureWave Broadcom BCM94352HMB 802.11/ac/867Mb...               PC   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              0            0    N                 Y   \n",
       "1            5             24           31    N                 N   \n",
       "2            1              2            2    N                 N   \n",
       "3            1              0            0    N                 Y   \n",
       "4            5              0            0    N                 Y   \n",
       "5            5              0            0    N                 Y   \n",
       "6            3              1            2    N                 Y   \n",
       "7            4              1            1    N                 Y   \n",
       "8            1              0            0    N                 Y   \n",
       "9            5              3            4    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                               Pleasantly surprised   \n",
       "1  OnHub is a pretty no nonsense type router that...   \n",
       "2     None of them worked.  No functionality at all.   \n",
       "3                               just keep searching.   \n",
       "4                                         Five Stars   \n",
       "5               Good quality, works well and compact   \n",
       "6        in fact this is third China good. Demn s***   \n",
       "7                                               Good   \n",
       "8                           You get what you pay for   \n",
       "9                        Great for Windows 7 Laptop!   \n",
       "\n",
       "                                         review_body review_date  sentiment  \n",
       "0  I was very surprised at the high quality of th...  2015-08-31          1  \n",
       "1  I am a Google employee and had to chance to us...  2015-08-31          1  \n",
       "2  Bought cables in 3ft, 6ft and 9ft.  NONE of th...  2015-08-31          0  \n",
       "3                               nope, cheap and slow  2015-08-31          0  \n",
       "4           Excellent! Great value and does the job.  2015-08-31          1  \n",
       "5           Good quality,works well and compact size  2015-08-31          1  \n",
       "6  This demn tablet is just a Real Chinese produc...  2015-08-31          0  \n",
       "7  I am not sure I don't know if it is the tablet...  2015-08-31          1  \n",
       "8  After exactly 45 days, the screen went dark. P...  2015-08-31          0  \n",
       "9  Replaced my Intel Centrino 2230 with the BCM94...  2015-08-31          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "FILE_PATH = kagglehub.dataset_download(\"machharavikiran/amazon-reviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", FILE_PATH)\n",
    "\n",
    "df_reviews = FileManager.open_csv_file(FILE_PATH)\n",
    "df_reviews.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0862e765",
   "metadata": {},
   "source": [
    "# 1) Construcci贸n de la muestra M\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a9e5e",
   "metadata": {},
   "source": [
    "* **Instrucciones**: Construir una muestra `` que sea representativa de la poblaci贸n `` (a partir del dataset que recolectaste desde el inicio del curso). Tomando como base el conocimiento adquirido en la *Actividad 3 del M贸dulo 4*, generar谩s particiones `` de ``, donde cada `` cumple con los criterios definidos por las variables de caracterizaci贸n que identificaste previamente (`` ser谩 igual a la uni贸n de todos los ``). Para esta actividad, y a diferencia del paso previo, se deber谩 de tener especial cuidado para determinar el n煤mero de instancias que deber谩 contender cada partici贸n `` a generar, de tal forma que no se inyecte ning煤n tipo de sesgo que pueda alterar la calidad de los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044d45bb",
   "metadata": {},
   "source": [
    "## 1.1) Analizar la Distribuci贸n de las Variables Categ贸ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2308c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- An谩lisis de la Distribuci贸n de la Poblaci贸n (df_reviews) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuci贸n de las combinaciones en la poblaci贸n:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>vine</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>823420</td>\n",
       "      <td>11.922281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>36069</td>\n",
       "      <td>0.522242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>6046916</td>\n",
       "      <td>87.553174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>159</td>\n",
       "      <td>0.002302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  verified_purchase vine    count  percentage\n",
       "0                 N    N   823420   11.922281\n",
       "1                 N    Y    36069    0.522242\n",
       "2                 Y    N  6046916   87.553174\n",
       "3                 Y    Y      159    0.002302"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = [\"verified_purchase\", \"vine\"]\n",
    "\n",
    "print(\"--- An谩lisis de la Distribuci贸n de la Poblaci贸n (df_reviews) ---\")\n",
    "\n",
    "# Contar las ocurrencias de cada combinaci贸n de las variables categ贸ricas\n",
    "population_distribution = df_reviews.groupBy(categorical_cols).count()\n",
    "population_distribution = population_distribution.withColumn(\n",
    "    \"percentage\", (F.col(\"count\") / df_reviews.count()) * 100\n",
    ").orderBy(categorical_cols)\n",
    "\n",
    "print(\"\\nDistribuci贸n de las combinaciones en la poblaci贸n:\")\n",
    "population_distribution.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe64b1",
   "metadata": {},
   "source": [
    "En esta primera etapa del proceso, se realiza un an谩lisis exploratorio de la distribuci贸n de la poblaci贸n original (`df_reviews`) con base en dos variables categ贸ricas seleccionadas: `verified_purchase` y `vine`. A diferencia del entregable previo, en esta ocasi贸n se decidi贸 excluir la variable `star_rating` del conjunto de variables de caracterizaci贸n. Esta decisi贸n responde a un hallazgo clave derivado del an谩lisis supervisado anterior, donde se identific贸 que `star_rating` guarda una correlaci贸n directa y significativa con la variable objetivo `sentiment`, lo cual podr铆a introducir un sesgo indeseado en la construcci贸n de la muestra representativa. Mantener 煤nicamente variables neutras y no directamente relacionadas con la etiqueta de salida garantiza una segmentaci贸n m谩s imparcial y metodol贸gicamente s贸lida.\n",
    "\n",
    "El an谩lisis de distribuci贸n revela que la gran mayor铆a de las observaciones corresponde a rese帽as verificadas (`verified_purchase = Y`) y no asociadas al programa Vine (`vine = N`), representando aproximadamente el 87.55% del total. Otras combinaciones, como rese帽as no verificadas (`verified_purchase = N`) o aquellas marcadas como parte del programa Vine (`vine = Y`), conforman proporciones mucho menores. Este paso es fundamental ya que permite identificar las proporciones reales de cada estrato dentro de la poblaci贸n y constituye la base para una posterior selecci贸n muestral proporcional, asegurando que la muestra `` sea verdaderamente representativa de la poblaci贸n ``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1f8e98",
   "metadata": {},
   "source": [
    "## 1.2) Determinar el Tama帽o de la Muestra (M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39413582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de registros en la poblaci贸n: 6906564\n",
      "Tama帽o de la muestra deseado (aprox. 10.0%): 690656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Vamos a definir un tama帽o de muestra. Para este ejemplo, usemos el 10% del total de registros.\n",
    "# Puedes ajustar este valor seg煤n tus necesidades y recursos.\n",
    "sample_fraction = 0.1\n",
    "total_population_count = df_reviews.count()\n",
    "sample_size = int(total_population_count * sample_fraction)\n",
    "\n",
    "print(f\"Total de registros en la poblaci贸n: {total_population_count}\")\n",
    "print(f\"Tama帽o de la muestra deseado (aprox. {sample_fraction*100}%): {sample_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90767488",
   "metadata": {},
   "source": [
    "En esta segunda etapa se define el tama帽o de la muestra `` que ser谩 extra铆da de la poblaci贸n ``, con el prop贸sito de construir un subconjunto representativo que preserve la estructura y diversidad de los datos originales. Para este fin, se estableci贸 un valor de muestreo equivalente al **10% del total de registros disponibles**. Esta proporci贸n fue seleccionada con base en criterios metodol贸gicos y computacionales, considerando tanto la escala del conjunto de datos como los objetivos del an谩lisis posterior.\n",
    "\n",
    "Desde el punto de vista estad铆stico, una fracci贸n del 10% resulta suficiente para capturar patrones relevantes y garantizar una adecuada representaci贸n de las combinaciones categ贸ricas identificadas previamente, incluso en escenarios donde algunos estratos presentan baja frecuencia relativa. Adem谩s, esta decisi贸n permite mantener un equilibrio adecuado entre la fidelidad de la muestra y la eficiencia computacional, particularmente importante en contextos de Big Data donde el volumen de informaci贸n puede impactar significativamente el rendimiento de las operaciones.\n",
    "\n",
    "Al delimitar expl铆citamente el tama帽o de la muestra, se establece un marco cuantitativo claro que orienta la distribuci贸n proporcional de las instancias en cada segmento, evitando sesgos y distorsiones en las etapas siguientes del an谩lisis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e4f20",
   "metadata": {},
   "source": [
    "## 1.3) Calcular el N煤mero de Instancias por Partici贸n (Mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c94d7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Distribuci贸n Deseada de la Muestra y Conteo por Partici贸n ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('N', 'N'): 82342.0,\n",
       " ('N', 'Y'): 3607.0,\n",
       " ('Y', 'N'): 604691.0,\n",
       " ('Y', 'Y'): 16.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular el n煤mero de instancias para cada combinaci贸n en la muestra\n",
    "print(\"--- Distribuci贸n Deseada de la Muestra y Conteo por Partici贸n ---\")\n",
    "\n",
    "sample_distribution = population_distribution.withColumn(\n",
    "    \"sample_count\", F.round(F.col(\"percentage\") * sample_size / 100)\n",
    ")\n",
    "sample_distribution.toPandas() # Muestra el conteo deseado para cada partici贸n en la muestra\n",
    "\n",
    "# Convertir a un diccionario para facilitar la selecci贸n de la muestra estratificada\n",
    "sample_counts_dict = {\n",
    "    tuple(row[col] for col in categorical_cols): row[\"sample_count\"]\n",
    "    for row in sample_distribution.collect()\n",
    "}\n",
    "sample_counts_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfecead0",
   "metadata": {},
   "source": [
    "Se procede a determinar la distribuci贸n deseada de la muestra representativa ``, en funci贸n de las proporciones previamente observadas en la poblaci贸n `` respecto a las variables categ贸ricas seleccionadas: `verified_purchase` y `vine`. Para ello, se calcula la cantidad de instancias que cada combinaci贸n posible de estas variables deber谩 contener dentro de la muestra, con base en su porcentaje de representaci贸n original y el tama帽o total previamente definido para `` (10% del total poblacional).\n",
    "\n",
    "Este procedimiento tiene como objetivo preservar la estructura interna de la poblaci贸n, garantizando que la muestra conserve de manera proporcional la diversidad y distribuci贸n de los distintos perfiles existentes en los datos. En otras palabras, se busca construir una muestra estratificada que refleje fielmente la composici贸n original de los datos en t茅rminos de las variables de caracterizaci贸n elegidas.\n",
    "\n",
    "Los resultados obtenidos muestran que la combinaci贸n m谩s frecuente es `('Y', 'N')`, correspondiente a registros de usuarios que realizaron una compra verificada y que no pertenecen al programa Vine, con una representaci贸n esperada de aproximadamente 604,691 registros dentro de la muestra. Le siguen `('N', 'N')` con 82,342 registros, `('N', 'Y')` con 3,607, y `('Y', 'Y')` con solo 16 registros. Esta distribuci贸n, aunque desigual, es consistente con la frecuencia real de ocurrencia en la poblaci贸n y ser谩 la base para extraer de forma estratificada los registros que compondr谩n la muestra final ``.\n",
    "\n",
    "Este paso es esencial para asegurar que las particiones ``, construidas posteriormente a partir de ``, sean equilibradas, realistas y libres de sesgos de representaci贸n, lo que a su vez fortalece la validez estad铆stica de cualquier an谩lisis futuro derivado del conjunto muestral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a943b398",
   "metadata": {},
   "source": [
    "# 1.4) Generar la Muestra (M) de forma estratificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec531515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generando la Muestra (M) de forma Estratificada ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N煤mero de registros en la muestra final (M): 691829\n",
      "Muestra (M) generada. Mostrando las primeras 5 filas:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>112405</td>\n",
       "      <td>RKP98DQX0VTFZ</td>\n",
       "      <td>B00T91YABQ</td>\n",
       "      <td>541159143</td>\n",
       "      <td>Polare Thick Full Grain Leather Shoulder Brief...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Awesome Bag!</td>\n",
       "      <td>I bought this bag looking for a briefcase that...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>46558847</td>\n",
       "      <td>R3MSK0V0TDL01L</td>\n",
       "      <td>B00TKFDFW6</td>\n",
       "      <td>701421383</td>\n",
       "      <td>CybertronPC SOKOM-I Gaming Desktop - AMD FX-63...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>It's a Monster Machine</td>\n",
       "      <td>I bought a slightly modified version of this C...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>19852854</td>\n",
       "      <td>RM6KESMRIY1UQ</td>\n",
       "      <td>B00746W9F2</td>\n",
       "      <td>41875278</td>\n",
       "      <td>Apple iPad mini</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>very good price!</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>13443121</td>\n",
       "      <td>R2A948UZQGFZHO</td>\n",
       "      <td>B00KQE99C0</td>\n",
       "      <td>348236562</td>\n",
       "      <td>Standing Protective Case for Fire HD 7 (4th Ge...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Love it, it protects the screen and I love the...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>107911</td>\n",
       "      <td>RS1QTAUB8FJI0</td>\n",
       "      <td>B00JQZJ75E</td>\n",
       "      <td>937857628</td>\n",
       "      <td>iXCC Silicon Case Cover for Apple iPad Mini</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Nice case for the money. It is comfortable to ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US       112405   RKP98DQX0VTFZ  B00T91YABQ       541159143   \n",
       "1          US     46558847  R3MSK0V0TDL01L  B00TKFDFW6       701421383   \n",
       "2          US     19852854   RM6KESMRIY1UQ  B00746W9F2        41875278   \n",
       "3          US     13443121  R2A948UZQGFZHO  B00KQE99C0       348236562   \n",
       "4          US       107911   RS1QTAUB8FJI0  B00JQZJ75E       937857628   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  Polare Thick Full Grain Leather Shoulder Brief...               PC   \n",
       "1  CybertronPC SOKOM-I Gaming Desktop - AMD FX-63...               PC   \n",
       "2                                    Apple iPad mini               PC   \n",
       "3  Standing Protective Case for Fire HD 7 (4th Ge...               PC   \n",
       "4        iXCC Silicon Case Cover for Apple iPad Mini               PC   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              1            3    N                 N   \n",
       "1            5              1            1    N                 N   \n",
       "2            5              0            0    N                 N   \n",
       "3            5              0            0    N                 N   \n",
       "4            5              0            0    N                 N   \n",
       "\n",
       "          review_headline                                        review_body  \\\n",
       "0            Awesome Bag!  I bought this bag looking for a briefcase that...   \n",
       "1  It's a Monster Machine  I bought a slightly modified version of this C...   \n",
       "2              Five Stars                                   very good price!   \n",
       "3              Five Stars  Love it, it protects the screen and I love the...   \n",
       "4                 5 stars  Nice case for the money. It is comfortable to ...   \n",
       "\n",
       "  review_date  sentiment  \n",
       "0  2015-08-31          1  \n",
       "1  2015-08-31          1  \n",
       "2  2015-08-31          1  \n",
       "3  2015-08-31          1  \n",
       "4  2015-08-31          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para asegurar la representatividad, realizaremos un muestreo estratificado.\n",
    "# Esto implica muestrear cada \"estrato\" (combinaci贸n de categor铆as) por separado para asegurar las proporciones deseadas.\n",
    "print(\"--- Generando la Muestra (M) de forma Estratificada ---\")\n",
    "\n",
    "sample_df = spark.createDataFrame([], df_reviews.schema) # DataFrame vac铆o para la muestra\n",
    "\n",
    "for combo_values, count_needed in sample_counts_dict.items():\n",
    "    if count_needed > 0:\n",
    "        filter_condition = None\n",
    "        for i, col_name in enumerate(categorical_cols):\n",
    "            if filter_condition is None:\n",
    "                filter_condition = (F.col(col_name) == combo_values[i])\n",
    "            else:\n",
    "                filter_condition = filter_condition & (F.col(col_name) == combo_values[i])\n",
    "\n",
    "        # Seleccionar las filas para el estrato actual\n",
    "        stratum_df = df_reviews.filter(filter_condition)\n",
    "\n",
    "        # Si el estrato tiene menos registros de los que necesitamos, tomamos todos.\n",
    "        # Si tiene m谩s, tomamos una muestra aleatoria del tama帽o deseado.\n",
    "        current_stratum_count = stratum_df.count()\n",
    "        if current_stratum_count > 0:\n",
    "            if count_needed < current_stratum_count:\n",
    "                # Tomamos una muestra aleatoria del tama帽o deseado\n",
    "                fraction = count_needed / current_stratum_count\n",
    "                sampled_stratum = stratum_df.sample(withReplacement=False, fraction=fraction, seed=42)\n",
    "            else:\n",
    "                # Si no hay suficientes registros en el estrato, tomamos todos los disponibles\n",
    "                sampled_stratum = stratum_df\n",
    "\n",
    "            # Unir al DataFrame de la muestra principal\n",
    "            sample_df = sample_df.unionAll(sampled_stratum)\n",
    "\n",
    "print(f\"N煤mero de registros en la muestra final (M): {sample_df.count()}\")\n",
    "print(\"Muestra (M) generada. Mostrando las primeras 5 filas:\")\n",
    "sample_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649893ba",
   "metadata": {},
   "source": [
    "En este paso se lleva a cabo la generaci贸n efectiva de la muestra `` mediante un proceso de **muestreo estratificado**. A diferencia de un muestreo aleatorio simple, el enfoque estratificado garantiza que cada subconjunto de inter茅s (en este caso, definido por las combinaciones de las variables categ贸ricas `verified_purchase` y `vine`) est茅 adecuadamente representado en la muestra final, en proporciones equivalentes a las observadas en la poblaci贸n ``.\n",
    "\n",
    "Para ello, se recorre cada combinaci贸n posible de valores previamente identificada y se extrae un subconjunto de registros desde el conjunto poblacional, aplicando una l贸gica condicional que asegura tanto la proporcionalidad deseada como la eficiencia computacional. En particular, cuando un estrato contiene m谩s registros que los requeridos, se realiza un muestreo aleatorio sin reemplazo proporcional a su tama帽o; en contraste, si el estrato es m谩s peque帽o que la cantidad esperada, se conservan todos los registros disponibles. Este tratamiento dual permite construir una muestra robusta, incluso en presencia de categor铆as minoritarias o desbalanceadas.\n",
    "\n",
    "El resultado final fue la obtenci贸n de una muestra `` con 691,829 registros, cifra levemente superior al valor estimado originalmente (690,656) debido a efectos de redondeo y disponibilidad real de datos en algunos estratos. Esta ligera discrepancia es aceptable dentro de un marco de an谩lisis exploratorio y no compromete la representatividad del conjunto, ya que la preservaci贸n de las proporciones entre categor铆as sigue siendo el criterio rector de la construcci贸n muestral.\n",
    "\n",
    "Como se puede apreciar, este paso sienta las bases para asegurar que cualquier inferencia posterior, basada en la muestra `` o en sus particiones ``, no est茅 sesgada por sobre o subrepresentaci贸n de ciertos grupos, manteniendo la integridad metodol贸gica del estudio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf18174",
   "metadata": {},
   "source": [
    "# 1.5) Crear las Particiones (Mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f080ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejemplo de partici贸n M_i (verified_purchase='Y', vine='N'): 605672 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>37802374</td>\n",
       "      <td>R2EY3N4K9W19UP</td>\n",
       "      <td>B00IFYEYXC</td>\n",
       "      <td>602496520</td>\n",
       "      <td>AzureWave Broadcom BCM94352HMB 802.11/ac/867Mb...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great for Windows 7 Laptop!</td>\n",
       "      <td>Replaced my Intel Centrino 2230 with the BCM94...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>29333557</td>\n",
       "      <td>R3G4RT3EQ9RSY7</td>\n",
       "      <td>B00MA40W9I</td>\n",
       "      <td>535866197</td>\n",
       "      <td>Egoway庐 New Laptop Battery for Apple A1309 A12...</td>\n",
       "      <td>PC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Totally wasted $60 on this battery</td>\n",
       "      <td>Totally wasted $60 on this battery.  Didn't wo...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>16160990</td>\n",
       "      <td>RW9VR7UKL3E69</td>\n",
       "      <td>B00HPQ0H0K</td>\n",
       "      <td>176437370</td>\n",
       "      <td>ARCTIC S111 USB-Powered Portable Stereo Speake...</td>\n",
       "      <td>PC</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>tinny sounding</td>\n",
       "      <td>tinny weak sound</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>48701722</td>\n",
       "      <td>R7ER63LS7Q1O5</td>\n",
       "      <td>B00RXEWOAA</td>\n",
       "      <td>540891596</td>\n",
       "      <td>3.5\" USB External Floppy Disk Drive Portable 1...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Love it</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>19280847</td>\n",
       "      <td>RAYGOWHX4H47</td>\n",
       "      <td>B001J226JQ</td>\n",
       "      <td>210607495</td>\n",
       "      <td>Generic USB to 9-pin Serial Port Adapter</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>perfect</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     37802374  R2EY3N4K9W19UP  B00IFYEYXC       602496520   \n",
       "1          US     29333557  R3G4RT3EQ9RSY7  B00MA40W9I       535866197   \n",
       "2          US     16160990   RW9VR7UKL3E69  B00HPQ0H0K       176437370   \n",
       "3          US     48701722   R7ER63LS7Q1O5  B00RXEWOAA       540891596   \n",
       "4          US     19280847    RAYGOWHX4H47  B001J226JQ       210607495   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  AzureWave Broadcom BCM94352HMB 802.11/ac/867Mb...               PC   \n",
       "1  Egoway庐 New Laptop Battery for Apple A1309 A12...               PC   \n",
       "2  ARCTIC S111 USB-Powered Portable Stereo Speake...               PC   \n",
       "3  3.5\" USB External Floppy Disk Drive Portable 1...               PC   \n",
       "4           Generic USB to 9-pin Serial Port Adapter               PC   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              3            4    N                 Y   \n",
       "1            1              0            0    N                 Y   \n",
       "2            2              0            0    N                 Y   \n",
       "3            5              0            0    N                 Y   \n",
       "4            5              0            0    N                 Y   \n",
       "\n",
       "                      review_headline  \\\n",
       "0         Great for Windows 7 Laptop!   \n",
       "1  Totally wasted $60 on this battery   \n",
       "2                      tinny sounding   \n",
       "3                          Five Stars   \n",
       "4                          Five Stars   \n",
       "\n",
       "                                         review_body review_date  sentiment  \n",
       "0  Replaced my Intel Centrino 2230 with the BCM94...  2015-08-31          1  \n",
       "1  Totally wasted $60 on this battery.  Didn't wo...  2015-08-31          0  \n",
       "2                                   tinny weak sound  2015-08-31          0  \n",
       "3                                            Love it  2015-08-31          1  \n",
       "4                                            perfect  2015-08-31          1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Una vez que tenemos la muestra (sample_df), las particiones Mi son simplemente subconjuntos de esta \n",
    "# muestra basados en las combinaciones de las variables categ贸ricas.\n",
    "# No es necesario almacenar cada Mi por separado si se va a trabajar con ellos de forma iterativa o agrupada. \n",
    "# Podemos simplemente agrupar por las variables categ贸ricas cuando sea necesario.\n",
    "\n",
    "# Si se necesita acceder a una partici贸n espec铆fica (Mi), se puede filtrar as铆:\n",
    "# Ejemplo: Partici贸n para verified_purchase='Y', vine='N'\n",
    "mi_example = sample_df.filter((F.col(\"verified_purchase\") == \"Y\") &\n",
    "                              (F.col(\"vine\") == \"N\"))\n",
    "print(f\"\\nEjemplo de partici贸n M_i (verified_purchase='Y', vine='N'): {mi_example.count()} registros\")\n",
    "mi_example.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a71c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creando las Particiones (Mi) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribuci贸n REAL de las combinaciones en la Muestra (M):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>vine</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>82555</td>\n",
       "      <td>11.932862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>3583</td>\n",
       "      <td>0.517903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>605672</td>\n",
       "      <td>87.546489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>19</td>\n",
       "      <td>0.002746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  verified_purchase vine   count  percentage\n",
       "0                 N    N   82555   11.932862\n",
       "1                 N    Y    3583    0.517903\n",
       "2                 Y    N  605672   87.546489\n",
       "3                 Y    Y      19    0.002746"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"--- Creando las Particiones (Mi) ---\")\n",
    "\n",
    "# Verificamos que las proporciones se mantengan.\n",
    "sample_actual_distribution = sample_df.groupBy(categorical_cols).count()\n",
    "sample_actual_distribution = sample_actual_distribution.withColumn(\n",
    "    \"percentage\", (F.col(\"count\") / sample_df.count()) * 100\n",
    ").orderBy(categorical_cols)\n",
    "\n",
    "print(\"\\nDistribuci贸n REAL de las combinaciones en la Muestra (M):\")\n",
    "sample_actual_distribution.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0a2f29",
   "metadata": {},
   "source": [
    "En esta 煤ltima fase del proceso se formaliza la creaci贸n de las particiones ``, definidas como subconjuntos disjuntos de la muestra ``, cuya segmentaci贸n responde a las combinaciones 煤nicas de las variables categ贸ricas seleccionadas. Dado que la muestra fue construida de manera estratificada en funci贸n de estas mismas variables, el agrupamiento por sus valores permite recuperar de forma directa cada una de las particiones sin necesidad de duplicar datos ni mantener estructuras adicionales.\n",
    "\n",
    "Este dise帽o no solo reduce el costo computacional, sino que ofrece flexibilidad metodol贸gica: cada partici贸n puede ser invocada y procesada din谩micamente seg煤n los requerimientos del an谩lisis posterior. Por ejemplo, acceder a la partici贸n \n",
    "`` correspondiente a `verified_purchase='Y'` y `vine='N'` permite trabajar exclusivamente con ese segmento de usuarios, aislando su comportamiento o caracter铆sticas para estudios comparativos.\n",
    "\n",
    "Al verificar la distribuci贸n real de las combinaciones dentro de la muestra generada, se confirma que las proporciones han sido exitosamente conservadas. Las diferencias con respecto a los valores esperados son m铆nimas y atribuibles al redondeo y a la disponibilidad efectiva de registros dentro de ciertos estratos, sin comprometer la validez del enfoque.\n",
    "\n",
    "Este paso final garantiza que cada partici贸n sea estad铆sticamente coherente con su representaci贸n en la poblaci贸n ``, eliminando riesgos de sesgo por subrepresentaci贸n o sobreajuste a grupos espec铆ficos. Este dise帽o habilita un an谩lisis posterior m谩s s贸lido y confiable, ajustado a los principios fundamentales de muestreo en escenarios de datos masivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95ee2a9",
   "metadata": {},
   "source": [
    "# 2) Construcci贸n Train  Test\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaf68b3",
   "metadata": {},
   "source": [
    "* **Instrucciones**: Construcci贸n del conjunto de entrenamiento y prueba. Para este paso se asume que `` = {``: `` es una partici贸n derivada de las variables de caracterizaci贸n de la poblaci贸n} generada en el paso anterior. Para construir el conjunto de entrenamiento y prueba, se debe de calcular el porcentaje de divisi贸n a usar, de tal forma que al dividir cada `` en un conjunto de entrenamiento (****) y prueba (****), no se inyecten sesgos que desv铆en la probabilidad de ocurrencia de los patrones en cada nueva partici贸n. Para ello, deber谩s de retomar la estrategia de muestreo propuesta en el paso 4 de la Actividad 3 del m贸dulo 4. Se debe de cuidar que `   = `, adem谩s de que la uni贸n de todas las particiones es igual a ``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7e8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(verified_purchase='N', vine='N'),\n",
       " Row(verified_purchase='N', vine='Y'),\n",
       " Row(verified_purchase='Y', vine='N'),\n",
       " Row(verified_purchase='Y', vine='Y')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir la proporci贸n de divisi贸n\n",
    "train_ratio = 0.7\n",
    "test_ratio = 1 - train_ratio\n",
    "seed = 42\n",
    "\n",
    "# Diccionarios para almacenar los conjuntos de entrenamiento y prueba por partici贸n\n",
    "train_partitions = {} # { (verified_purchase, vine): DataFrame_Tri }\n",
    "test_partitions = {}  # { (verified_purchase, vine): DataFrame_Tsi }\n",
    "\n",
    "# Obtener todas las combinaciones 煤nicas de las variables categ贸ricas en la muestra (M)\n",
    "distinct_combinations = sample_df.select(categorical_cols).distinct().collect()\n",
    "distinct_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dad3db",
   "metadata": {},
   "source": [
    "La definici贸n de una proporci贸n de **70/30** para los conjuntos de entrenamiento y prueba responde a una pr谩ctica com煤nmente aceptada en el 谩mbito del an谩lisis de datos, ya que permite un equilibrio adecuado entre aprendizaje y validaci贸n. El uso de una semilla asegura la reproducibilidad del proceso, lo cual es fundamental en entornos experimentales. \n",
    "\n",
    "Por otro lado, la identificaci贸n expl铆cita de las combinaciones presentes en la muestra evita errores asociados al redondeo o a la ausencia de estratos poco frecuentes, garantizando que la divisi贸n se realice 煤nicamente sobre particiones efectivamente representadas. El resultado obtenido (cuatro combinaciones 煤nicas) confirma que la muestra mantiene la diversidad estructural necesaria para una segmentaci贸n estratificada v谩lida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67936ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando partici贸n Mi para: ('N', 'N')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTama帽o de Mi: 82555 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTama帽o de Tri: 57790 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTama帽o de Tsi: 24765 registros\n",
      "\n",
      "Procesando partici贸n Mi para: ('N', 'Y')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTama帽o de Mi: 3583 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTama帽o de Tri: 2455 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTama帽o de Tsi: 1128 registros\n",
      "\n",
      "Procesando partici贸n Mi para: ('Y', 'N')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTama帽o de Mi: 605672 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTama帽o de Tri: 424081 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTama帽o de Tsi: 181591 registros\n",
      "\n",
      "Procesando partici贸n Mi para: ('Y', 'Y')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTama帽o de Mi: 19 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTama帽o de Tri: 16 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 113:===================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTama帽o de Tsi: 3 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Iterar sobre cada combinaci贸n para crear las particiones Mi y dividirlas\n",
    "for row in distinct_combinations:\n",
    "    combo_values = tuple(row[col] for col in categorical_cols)\n",
    "    print(f\"\\nProcesando partici贸n Mi para: {combo_values}\")\n",
    "\n",
    "    # Aislamos la Partici贸n Mi con apoyo de un filtro\n",
    "    filter_condition = None\n",
    "    for i, col_name in enumerate(categorical_cols):\n",
    "        if filter_condition is None:\n",
    "            filter_condition = (F.col(col_name) == combo_values[i])\n",
    "        else:\n",
    "            filter_condition = filter_condition & (F.col(col_name) == combo_values[i])\n",
    "\n",
    "    mi_df = sample_df.filter(filter_condition)\n",
    "    mi_count = mi_df.count()\n",
    "    print(f\"\\tTama帽o de Mi: {mi_count} registros\")\n",
    "\n",
    "    # Dividimos la Partici贸n Mi en Tri y Tsi\n",
    "    if mi_count > 0:\n",
    "        # randomSplit distribuye los datos aleatoriamente seg煤n las proporciones dadas\n",
    "        tri, tsi = mi_df.randomSplit([train_ratio, test_ratio], seed=seed)\n",
    "\n",
    "        # Almacenar las particiones resultantes\n",
    "        train_partitions[combo_values] = tri\n",
    "        test_partitions[combo_values] = tsi\n",
    "\n",
    "        print(f\"\\tTama帽o de Tri: {tri.count()} registros\")\n",
    "        print(f\"\\tTama帽o de Tsi: {tsi.count()} registros\")\n",
    "    else:\n",
    "        print(f\"\\tPartici贸n Mi vac铆a. No se generar谩n Tri y Tsi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9b8f15",
   "metadata": {},
   "source": [
    "Con este c贸digo se hace la segmentaci贸n de la muestra representativa `` en subconjuntos de entrenamiento (``) y prueba (``) para cada una de las particiones ``, definidas previamente seg煤n las combinaciones 煤nicas de las variables categ贸ricas `verified_purchase` y `vine`. Esta estrategia garantiza que el proceso de entrenamiento y evaluaci贸n se lleve a cabo respetando la estructura interna de la poblaci贸n original, evitando as铆 la introducci贸n de sesgos derivados de una partici贸n aleatoria no estratificada.\n",
    "\n",
    "El m茅todo empleado consiste en filtrar individualmente cada estrato ``, y aplicar la funci贸n `randomSplit` de PySpark para generar las correspondientes divisiones con una proporci贸n **70/30**. Esto permite mantener la representatividad estad铆stica dentro de cada combinaci贸n de atributos. Los resultados muestran que la distribuci贸n se ha respetado incluso en estratos de baja frecuencia, como el caso de la combinaci贸n `('Y', 'Y')`, donde se preserv贸 una divisi贸n razonable de 16 observaciones para entrenamiento y 3 para prueba.\n",
    "\n",
    "Esta partici贸n controlada por estrato es especialmente valiosa en contextos donde existen desequilibrios severos entre categor铆as, ya que permite evaluar el desempe帽o del modelo de forma equitativa sobre todos los grupos relevantes. Adem谩s, al evitar el solapamiento entre `` y ``, se salvaguarda la independencia entre fases de entrenamiento y validaci贸n, requisito esencial para asegurar la robustez metodol贸gica de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6c638cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verificaci贸n de las Condiciones ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama帽o de la muestra original (M): 691829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama帽o de la uni贸n de todos los Tri y Tsi: 691829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 158:====================================================>(151 + 1) / 152]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隆La condici贸n de uni贸n de particiones = M se cumple! Los conteos coinciden.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Verificamos las condiciones Tri  Tsi =  (no solapamiento) y la uni贸n de todas las particiones = M\n",
    "# Cabe destcar que la condici贸n Tri  Tsi =  se garantiza por la funci贸n `randomSplit` de Spark\n",
    "print(\"--- Verificaci贸n de las Condiciones ---\")\n",
    "\n",
    "# Uni贸n de todos los Tri\n",
    "all_tri_union = spark.createDataFrame([], sample_df.schema)\n",
    "for combo, tri_df in train_partitions.items():\n",
    "    all_tri_union = all_tri_union.unionAll(tri_df)\n",
    "\n",
    "# Uni贸n de todos los Tsi\n",
    "all_tsi_union = spark.createDataFrame([], sample_df.schema)\n",
    "for combo, tsi_df in test_partitions.items():\n",
    "    all_tsi_union = all_tsi_union.unionAll(tsi_df)\n",
    "\n",
    "# Uni贸n de todos los Tri y Tsi\n",
    "# Usamos distinct para manejar posibles duplicados si no hay garant铆a estricta\n",
    "final_union_m = all_tri_union.unionAll(all_tsi_union).distinct()\n",
    "\n",
    "print(f\"Tama帽o de la muestra original (M): {sample_df.count()}\")\n",
    "print(f\"Tama帽o de la uni贸n de todos los Tri y Tsi: {final_union_m.count()}\")\n",
    "\n",
    "# Si los conteos coinciden, la condici贸n se cumple.\n",
    "if sample_df.count() == final_union_m.count():\n",
    "    print(\"隆La condici贸n de uni贸n de particiones = M se cumple! Los conteos coinciden.\")\n",
    "else:\n",
    "    print(\"Advertencia: Los conteos de la uni贸n de particiones y la muestra M no coinciden.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f2cdd",
   "metadata": {},
   "source": [
    "Una vez realizadas las divisiones `` y `` correspondientes a cada partici贸n ``, se llev贸 a cabo un proceso de verificaci贸n para confirmar que se cumplan dos condiciones fundamentales de integridad en el dise帽o experimental: la no superposici贸n entre conjuntos de entrenamiento y prueba, es decir, `   = `, y la exhaustividad de la muestra, es decir, que la uni贸n de todas las particiones `  ` sea equivalente al conjunto original ``.\n",
    "\n",
    "La primera condici贸n se garantiza impl铆citamente mediante el uso de la funci贸n `randomSplit` de PySpark, la cual est谩 dise帽ada para generar subconjuntos mutuamente excluyentes a partir de un conjunto dado. En cuanto a la segunda condici贸n, se construy贸 la uni贸n de todas las particiones generadas y se aplic贸 una operaci贸n `distinct` para asegurar la unicidad de los registros. Al comparar el tama帽o de esta uni贸n con el total de registros de ``, se comprob贸 que ambos coinciden perfectamente, lo cual valida que no hubo p茅rdida ni duplicaci贸n de datos en el proceso de divisi贸n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a359f",
   "metadata": {},
   "source": [
    "# 3) Selecci贸n de m茅tricas para medir calidad de resultados\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4970a38e",
   "metadata": {},
   "source": [
    "Con el objetivo de evaluar la calidad de los resultados obtenidos a partir de los modelos implementados, es fundamental seleccionar cuidadosamente las **m茅tricas de desempe帽o**, considerando no solo la naturaleza del algoritmo (supervisado o no supervisado), sino tambi茅n el volumen de datos procesado y las implicaciones computacionales de cada m茅trica en un entorno de Big Data.\n",
    "\n",
    "En el caso del modelo `RandomForestClassifier`, al tratarse de un enfoque supervisado orientado a la clasificaci贸n, se seleccionaron m茅tricas est谩ndar pero robustas que permiten evaluar el desempe帽o general y por clase del modelo. Espec铆ficamente, se consideran las siguientes: **accuracy, precision, recall y F1-score**, todas en su versi贸n ponderada. Estas m茅tricas permiten analizar no solo el n煤mero de aciertos globales, sino tambi茅n la capacidad del modelo para distinguir correctamente entre las clases positivas y negativas, lo cual es especialmente relevante ante posibles desbalances en los datos. Adicionalmente, se utilizar谩 la **matriz de confusi贸n** como instrumento visual y cuantitativo que permite comprender la naturaleza de los errores cometidos (falsos positivos y falsos negativos), lo cual enriquece el an谩lisis m谩s all谩 de los valores promedio.\n",
    "\n",
    "Por otro lado, para el modelo `KMeans`, al ser un algoritmo no supervisado de agrupamiento, las m茅tricas tradicionales de clasificaci贸n no resultan aplicables. En su lugar, se opt贸 por la utilizaci贸n del **Silhouette Score**, el cual mide qu茅 tan similares son los puntos dentro de un mismo cl煤ster en comparaci贸n con puntos de otros cl煤sters. Esta m茅trica, adem谩s de ser ampliamente aceptada en tareas de agrupamiento, resulta computacionalmente viable en PySpark y permite inferir si el n煤mero de cl煤sters seleccionado es coherente con la estructura de los datos. Complementariamente, se evaluar谩 la **coherencia sem谩ntica de los cl煤sters obtenidos mediante inspecci贸n manual y an谩lisis de centroides promedio**, especialmente al comparar los resultados con la variable de salida conocida, lo que permite explorar la alineaci贸n entre los patrones descubiertos de manera no supervisada y las etiquetas originales.\n",
    "\n",
    "La selecci贸n de estas m茅tricas responde a la doble necesidad de garantizar interpretabilidad y precisi贸n en el an谩lisis, al tiempo que se respeta la escalabilidad exigida por el tratamiento de grandes vol煤menes de datos. La diversidad de enfoques implementados (supervisado y no supervisado) permite explorar diferentes dimensiones del comportamiento de los datos y establecer comparaciones que fortalecen la comprensi贸n del problema y la calidad de las soluciones construidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37251ff",
   "metadata": {},
   "source": [
    "# 4) Entrenamiento de Modelos de Aprendizaje\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df7074",
   "metadata": {},
   "source": [
    "## 4.1) Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb0e238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Convertir las columnas categ贸ricas a 铆ndices num茅ricos\n",
    "indexer_verified = StringIndexer(inputCol=\"verified_purchase\", outputCol=\"verified_purchase_index\", handleInvalid=\"skip\")\n",
    "indexer_vine = StringIndexer(inputCol=\"vine\", outputCol=\"vine_index\", handleInvalid=\"skip\")\n",
    "\n",
    "label_col = \"sentiment\"\n",
    "label_indexer = StringIndexer(inputCol=label_col, outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26245ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 167:===================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros despu茅s de eliminar nulos: 691829 (original: 691829)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Manejo de valores nulos \n",
    "initial_cols_to_check_for_nulls = [\n",
    "    \"helpful_votes\", \n",
    "    \"total_votes\", \n",
    "    \"verified_purchase\", \n",
    "    \"vine\", \n",
    "    \"sentiment\" # Label\n",
    "]\n",
    "\n",
    "sample_df_cleaned = sample_df.na.drop(subset=initial_cols_to_check_for_nulls)\n",
    "print(f\"Registros despu茅s de eliminar nulos: {sample_df_cleaned.count()} (original: {sample_df.count()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b229fa6",
   "metadata": {},
   "source": [
    "No se detectaron nulos, por lo que no se tiene que re-ejecutar el muestreo y la creaci贸n de particiones sobre sample_df_cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40564d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici贸n de las columnas que ser谩n ensambladas en el vector de caracter铆sticas\n",
    "feature_cols_for_assembler = [\n",
    "    \"helpful_votes\", \n",
    "    \"total_votes\", \n",
    "    \"verified_purchase_index\", \n",
    "    \"vine_index\"\n",
    "]\n",
    "\n",
    "vector_assembler = VectorAssembler(inputCols=feature_cols_for_assembler, outputCol=\"raw_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b781e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C贸digo para escalar las caracter铆sticas\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"raw_features\", \n",
    "    outputCol=\"scaled_features\", \n",
    "    withStd=True, \n",
    "    withMean=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb306819",
   "metadata": {},
   "source": [
    "## 4.2) Entrenamiento y evaluaci贸n de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "179d2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, ClusteringEvaluator\n",
    "\n",
    "# Diccionarios para almacenar los resultados de la evaluaci贸n\n",
    "rf_evaluation_results = {}\n",
    "kmeans_evaluation_results = {}\n",
    "\n",
    "# Definimos los modelos con hiperpar谩metros iniciales (se tunear谩n despu茅s)\n",
    "rf_model_instance = RandomForestClassifier(\n",
    "    featuresCol=\"scaled_features\", \n",
    "    labelCol=\"label\", \n",
    "    numTrees=20, \n",
    "    maxDepth=5, \n",
    "    seed=42\n",
    ")\n",
    "\n",
    "kmeans_model_instance = KMeans(\n",
    "    featuresCol=\"scaled_features\", \n",
    "    k=2, \n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Definimos los evaluadores\n",
    "rf_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "kmeans_evaluator = ClusteringEvaluator(\n",
    "    featuresCol=\"scaled_features\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"silhouette\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e147c203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando partici贸n: ('N', 'N') (Train: 57790, Test: 24765)\n",
      "\tEntrenando RandomForestClassifier para ('N', 'N')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandomForest Metrics:\n",
      "\t\tAccuracy: 0.6609\n",
      "\t\tF1-Score (Weighted): 0.5271\n",
      "\t\tPrecision (Weighted): 0.6790\n",
      "\t\tRecall (Weighted): 0.6609\n",
      "\n",
      "\tMatriz de Confusi贸n (RandomForest):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  prediction  count\n",
       "0    0.0         0.0  16348\n",
       "1    0.0         1.0      8\n",
       "2    1.0         0.0   8389\n",
       "3    1.0         1.0     20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntrenando KMeans para ('N', 'N')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKMeans Metrics:\n",
      "\t\tSilhouette Score: 0.9999\n",
      "\t\tWCSS: 50143.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando partici贸n: ('N', 'Y') (Train: 2455, Test: 1128)\n",
      "\tEntrenando RandomForestClassifier para ('N', 'Y')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandomForest Metrics:\n",
      "\t\tAccuracy: 0.7757\n",
      "\t\tF1-Score (Weighted): 0.6777\n",
      "\t\tPrecision (Weighted): 0.6017\n",
      "\t\tRecall (Weighted): 0.7757\n",
      "\n",
      "\tMatriz de Confusi贸n (RandomForest):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  prediction  count\n",
       "0    0.0         0.0    875\n",
       "1    1.0         0.0    253"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntrenando KMeans para ('N', 'Y')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKMeans Metrics:\n",
      "\t\tSilhouette Score: 0.9992\n",
      "\t\tWCSS: 1383.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando partici贸n: ('Y', 'N') (Train: 424081, Test: 181591)\n",
      "\tEntrenando RandomForestClassifier para ('Y', 'N')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandomForest Metrics:\n",
      "\t\tAccuracy: 0.7788\n",
      "\t\tF1-Score (Weighted): 0.6820\n",
      "\t\tPrecision (Weighted): 0.6065\n",
      "\t\tRecall (Weighted): 0.7788\n",
      "\n",
      "\tMatriz de Confusi贸n (RandomForest):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  prediction   count\n",
       "0    0.0         0.0  141424\n",
       "1    1.0         0.0   40167"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntrenando KMeans para ('Y', 'N')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKMeans Metrics:\n",
      "\t\tSilhouette Score: 1.0000\n",
      "\t\tWCSS: 103277.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando partici贸n: ('Y', 'Y') (Train: 16, Test: 3)\n",
      "\tEntrenando RandomForestClassifier para ('Y', 'Y')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandomForest Metrics:\n",
      "\t\tAccuracy: 1.0000\n",
      "\t\tF1-Score (Weighted): 1.0000\n",
      "\t\tPrecision (Weighted): 1.0000\n",
      "\t\tRecall (Weighted): 1.0000\n",
      "\n",
      "\tMatriz de Confusi贸n (RandomForest):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  prediction  count\n",
       "0    0.0         0.0      3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntrenando KMeans para ('Y', 'Y')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 545:===================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKMeans Metrics:\n",
      "\t\tSilhouette Score: 0.9059\n",
      "\t\tWCSS: 5.15\n",
      "\n",
      "--- Entrenamiento y evaluaci贸n por partici贸n completados. ---\n",
      "Resultados de RandomForest: {('N', 'N'): {'accuracy': 0.6609327680193822, 'f1_score': 0.5271011415626842, 'weighted_precision': 0.6790089713851148, 'weighted_recall': 0.6609327680193823, 'confusion_matrix': [{'label': 0.0, 'prediction': 0.0, 'count': 16348}, {'label': 0.0, 'prediction': 1.0, 'count': 8}, {'label': 1.0, 'prediction': 0.0, 'count': 8389}, {'label': 1.0, 'prediction': 1.0, 'count': 20}]}, ('N', 'Y'): {'accuracy': 0.775709219858156, 'f1_score': 0.6777289739150141, 'weighted_precision': 0.601724793772949, 'weighted_recall': 0.775709219858156, 'confusion_matrix': [{'label': 0.0, 'prediction': 0.0, 'count': 875}, {'label': 1.0, 'prediction': 0.0, 'count': 253}]}, ('Y', 'N'): {'accuracy': 0.7788051169936836, 'f1_score': 0.6819604963590836, 'weighted_precision': 0.6065374102555452, 'weighted_recall': 0.7788051169936836, 'confusion_matrix': [{'label': 0.0, 'prediction': 0.0, 'count': 141424}, {'label': 1.0, 'prediction': 0.0, 'count': 40167}]}, ('Y', 'Y'): {'accuracy': 1.0, 'f1_score': 1.0, 'weighted_precision': 1.0, 'weighted_recall': 1.0, 'confusion_matrix': [{'label': 0.0, 'prediction': 0.0, 'count': 3}]}}\n",
      "Resultados de KMeans: {('N', 'N'): {'silhouette_score': 0.9999486445701851, 'wcss': 50143.414153751924}, ('N', 'Y'): {'silhouette_score': 0.9992155633311729, 'wcss': 1383.1922442937162}, ('Y', 'N'): {'silhouette_score': 0.9999977190848507, 'wcss': 103277.30536698787}, ('Y', 'Y'): {'silhouette_score': 0.905864022247715, 'wcss': 5.149146096746269}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Bucle para entrenar y evaluar en cada partici贸n\n",
    "for combo_values, tri_df in train_partitions.items():\n",
    "    tsi_df = test_partitions[combo_values]\n",
    "    print(f\"\\nProcesando partici贸n: {combo_values} (Train: {tri_df.count()}, Test: {tsi_df.count()})\")\n",
    "\n",
    "    # --- RandomForestClassifier ---\n",
    "    print(f\"\\tEntrenando RandomForestClassifier para {combo_values}...\")\n",
    "    rf_pipeline = Pipeline(stages=[\n",
    "        indexer_verified,\n",
    "        indexer_vine,\n",
    "        vector_assembler,\n",
    "        scaler,\n",
    "        label_indexer,\n",
    "        rf_model_instance\n",
    "    ])\n",
    "\n",
    "    # Ejecutar pipeline de RF\n",
    "    rf_fitted_pipeline = rf_pipeline.fit(tri_df)\n",
    "\n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    rf_predictions = rf_fitted_pipeline.transform(tsi_df)\n",
    "\n",
    "    # Evaluar RandomForestClassifier\n",
    "    accuracy = rf_evaluator.evaluate(rf_predictions, {rf_evaluator.metricName: \"accuracy\"})\n",
    "    f1_score = rf_evaluator.evaluate(rf_predictions, {rf_evaluator.metricName: \"f1\"})\n",
    "    weighted_precision = rf_evaluator.evaluate(rf_predictions, {rf_evaluator.metricName: \"weightedPrecision\"})\n",
    "    weighted_recall = rf_evaluator.evaluate(rf_predictions, {rf_evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "    print(f\"\\tRandomForest Metrics:\")\n",
    "    print(f\"\\t\\tAccuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\t\\tF1-Score (Weighted): {f1_score:.4f}\")\n",
    "    print(f\"\\t\\tPrecision (Weighted): {weighted_precision:.4f}\")\n",
    "    print(f\"\\t\\tRecall (Weighted): {weighted_recall:.4f}\")\n",
    "\n",
    "    # Matriz de Confusi贸n\n",
    "    print(\"\\n\\tMatriz de Confusi贸n (RandomForest):\")\n",
    "    confusion_pdf = rf_predictions.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\").toPandas()\n",
    "    display(confusion_pdf)\n",
    "\n",
    "    rf_evaluation_results[combo_values] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"weighted_precision\": weighted_precision,\n",
    "        \"weighted_recall\": weighted_recall,\n",
    "        \"confusion_matrix\": confusion_pdf.to_dict('records') # Almacenar como lista de dicts\n",
    "    }\n",
    "\n",
    "    # --- KMeans ---\n",
    "    print(f\"\\tEntrenando KMeans para {combo_values}...\")\n",
    "    kmeans_pipeline = Pipeline(stages=[\n",
    "        indexer_verified,\n",
    "        indexer_vine,\n",
    "        vector_assembler,\n",
    "        scaler,\n",
    "        kmeans_model_instance\n",
    "    ])\n",
    "\n",
    "    # Ejecutar pipeline de KMeans\n",
    "    kmeans_fitted_pipeline = kmeans_pipeline.fit(tri_df)\n",
    "\n",
    "    # Realizar predicciones de cl煤steres en la misma partici贸n de entrenamiento para evaluaci贸n\n",
    "    # (KMeans es no supervisado, evaluamos la estructura de los cl煤steres en los datos que us贸 para aprender)\n",
    "    kmeans_predictions = kmeans_fitted_pipeline.transform(tri_df)\n",
    "\n",
    "    # Evaluar KMeans\n",
    "    silhouette_score = kmeans_evaluator.evaluate(kmeans_predictions)\n",
    "    # WCSS (Within-Cluster Sum of Squared Errors) se obtiene del modelo KMeans ajustado\n",
    "    wcss = kmeans_fitted_pipeline.stages[-1].summary.trainingCost\n",
    "\n",
    "    print(f\"\\tKMeans Metrics:\")\n",
    "    print(f\"\\t\\tSilhouette Score: {silhouette_score:.4f}\")\n",
    "    print(f\"\\t\\tWCSS: {wcss:.2f}\")\n",
    "\n",
    "    kmeans_evaluation_results[combo_values] = {\n",
    "        \"silhouette_score\": silhouette_score,\n",
    "        \"wcss\": wcss\n",
    "    }\n",
    "\n",
    "print(\"\\n--- Entrenamiento y evaluaci贸n por partici贸n completados. ---\")\n",
    "print(\"Resultados de RandomForest:\", rf_evaluation_results)\n",
    "print(\"Resultados de KMeans:\", kmeans_evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52ca23",
   "metadata": {},
   "source": [
    "## 4.3) Ajuste de hiperpar谩metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Seleccionamos una partici贸n representativa para el ajuste de hiperpar谩metros:\n",
    "# Para este ejemplo, tomaremos la primera partici贸n de entrenamiento disponible.\n",
    "if not train_partitions:\n",
    "    print(\"No hay particiones de entrenamiento disponibles para el ajuste de hiperpar谩metros.\")\n",
    "else:\n",
    "    first_combo_key = list(train_partitions.keys())[0]\n",
    "    tuning_data_df = train_partitions[first_combo_key]\n",
    "    print(f\"Realizando ajuste de hiperpar谩metros en la partici贸n: {first_combo_key} (Tama帽o: {tuning_data_df.count()})\")\n",
    "\n",
    "    print(\"\\n  Ajustando Hiperpar谩metros para RandomForestClassifier...\")\n",
    "\n",
    "    # Instanciamos un nuevo RandomForestClassifier (sin numTrees y maxDepth espec铆ficos aqu铆, se definir谩n en ParamGrid)\n",
    "    rf_tune_model_instance = RandomForestClassifier(\n",
    "        featuresCol=\"scaled_features\", \n",
    "        labelCol=\"label\", \n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # Reconstruimos el pipeline de RF para tuning, usando la instancia `rf_tune_model_instance`\n",
    "    rf_tune_pipeline = Pipeline(stages=[\n",
    "        indexer_verified,\n",
    "        indexer_vine,\n",
    "        vector_assembler,\n",
    "        scaler,\n",
    "        label_indexer,\n",
    "        rf_tune_model_instance\n",
    "    ])\n",
    "\n",
    "    # Definir la cuadr铆cula de par谩metros a probar\n",
    "    rf_paramGrid = (ParamGridBuilder()\n",
    "                    .addGrid(rf_tune_model_instance.numTrees, [10, 50]) \n",
    "                    .addGrid(rf_tune_model_instance.maxDepth, [5, 10])  \n",
    "                    .addGrid(rf_tune_model_instance.minInstancesPerNode, [1, 5]) \n",
    "                    .build())\n",
    "\n",
    "    # Crear el CrossValidator\n",
    "    rf_crossval = CrossValidator(estimator=rf_tune_pipeline,\n",
    "                                 estimatorParamMaps=rf_paramGrid,\n",
    "                                 evaluator=MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"f1\"), # Usar F1 para seleccionar el mejor modelo\n",
    "                                 numFolds=3, # N煤mero de folds para validaci贸n cruzada\n",
    "                                 seed=42,\n",
    "                                 parallelism=spark.sparkContext.defaultParallelism) # Usar todos los cores disponibles\n",
    "\n",
    "    # Entrenar el CrossValidator (puede tardar un tiempo considerable)\n",
    "    print(\"    Iniciando Cross-Validation para RandomForest... (Esto puede tomar tiempo)\")\n",
    "    rf_cv_model = rf_crossval.fit(tuning_data_df) # Entrenar en los datos de tuning\n",
    "    best_rf_pipeline_model = rf_cv_model.bestModel # El mejor pipeline entrenado\n",
    "\n",
    "    print(\"    Mejores Hiperpar谩metros encontrados para RandomForestClassifier:\")\n",
    "    best_rf_params = best_rf_pipeline_model.stages[-1].extractParamMap()\n",
    "    print(f\"      numTrees: {best_rf_params.get(rf_tune_model_instance.numTrees)}\")\n",
    "    print(f\"      maxDepth: {best_rf_params.get(rf_tune_model_instance.maxDepth)}\")\n",
    "    print(f\"      minInstancesPerNode: {best_rf_params.get(rf_tune_model_instance.minInstancesPerNode)}\")\n",
    "\n",
    "    # Puedes almacenar este `best_rf_pipeline_model` para usarlo en futuras inferencias o para re-evaluar las particiones.\n",
    "\n",
    "\n",
    "    # --- Ajuste de Hiperpar谩metros para KMeans ---\n",
    "    print(\"\\n  Ajustando Hiperpar谩metros para KMeans (k)...\")\n",
    "\n",
    "    # Instanciar un nuevo KMeans (sin k espec铆fico aqu铆)\n",
    "    kmeans_tune_model_instance = KMeans(featuresCol=\"scaled_features\", seed=42)\n",
    "\n",
    "    # Reconstruir el pipeline de KMeans para tuning\n",
    "    kmeans_tune_pipeline = Pipeline(stages=[\n",
    "        indexer_verified,\n",
    "        indexer_vine,\n",
    "        vector_assembler,\n",
    "        scaler,\n",
    "        kmeans_tune_model_instance\n",
    "    ])\n",
    "\n",
    "    # Definir la cuadr铆cula de par谩metros para k\n",
    "    kmeans_paramGrid = (ParamGridBuilder()\n",
    "                        .addGrid(kmeans_tune_model_instance.k, [2, 3, 4, 5]) # Probar diferentes n煤meros de cl煤steres\n",
    "                        .build())\n",
    "\n",
    "    # Crear el CrossValidator\n",
    "    kmeans_crossval = CrossValidator(estimator=kmeans_tune_pipeline,\n",
    "                                     estimatorParamMaps=kmeans_paramGrid,\n",
    "                                     evaluator=ClusteringEvaluator(featuresCol=\"scaled_features\", metricName=\"silhouette\"), # Usar Silhouette para seleccionar el mejor k\n",
    "                                     numFolds=3, # N煤mero de folds\n",
    "                                     seed=42,\n",
    "                                     parallelism=spark.sparkContext.defaultParallelism)\n",
    "\n",
    "    # Entrenar el CrossValidator\n",
    "    print(\"    Iniciando Cross-Validation para KMeans... (Esto puede tomar tiempo)\")\n",
    "    kmeans_cv_model = kmeans_crossval.fit(tuning_data_df) # Entrenar en los datos de tuning\n",
    "    best_kmeans_pipeline_model = kmeans_cv_model.bestModel # El mejor pipeline entrenado\n",
    "\n",
    "    print(\"    Mejor n煤mero de cl煤steres (k) encontrado para KMeans:\")\n",
    "    best_kmeans_k = best_kmeans_pipeline_model.stages[-1].getK()\n",
    "    print(f\"      k: {best_kmeans_k}\")\n",
    "\n",
    "    # Puedes almacenar este `best_kmeans_pipeline_model` para usarlo en futuras inferencias o an谩lisis de cl煤steres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d88f71",
   "metadata": {},
   "source": [
    "## 4.4) Almacenamiento y carga de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5dc520",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"/ml_models/\"\n",
    "\n",
    "# Guardamos el mejor modelo RandomForest\n",
    "if 'best_rf_pipeline_model' in locals():\n",
    "    rf_model_save_path = path.join(base_model_path, \"random_forest_sentiment_classifier\")\n",
    "    best_rf_pipeline_model.write().overwrite().save(rf_model_save_path)\n",
    "    print(\"Modelo RandomForest guardado exitosamente.\")\n",
    "\n",
    "# Guardamos el mejor modelo KMeans\n",
    "if 'best_kmeans_pipeline_model' in locals():\n",
    "    kmeans_model_save_path = path.join(base_model_path, \"kmeans_review_clusters\")\n",
    "    best_kmeans_pipeline_model.write().overwrite().save(kmeans_model_save_path)\n",
    "    print(\"Modelo KMeans guardado exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c761b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "# Ejemplo de c贸mo cargar el modelo (RandomForestClassifier)\n",
    "loaded_rf_model = PipelineModel.load(rf_model_save_path)\n",
    "print(\"Modelo RandomForest cargado exitosamente\")\n",
    "\n",
    "# Ejemplo de c贸mo cargar el modelo (KMeans)\n",
    "loaded_kmeans_model = PipelineModel.load(kmeans_model_save_path)\n",
    "print(\"Modelo KMeans cargado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d9975c",
   "metadata": {},
   "source": [
    "# 5) An谩lisis de resultados\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd3a43c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
