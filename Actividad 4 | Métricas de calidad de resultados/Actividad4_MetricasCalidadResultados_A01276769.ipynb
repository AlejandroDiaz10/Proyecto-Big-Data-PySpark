{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c667fc",
   "metadata": {},
   "source": [
    "# Actividad 4 | Métricas de calidad de resultados\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2888f4",
   "metadata": {},
   "source": [
    "**MAESTRÍA EN INTELIGENCIA ARTIFICIAL APLICADA**\n",
    "\n",
    "**Curso: TC4034.10 - Análisis de grandes volúmenes de datos**\n",
    "\n",
    "Tecnológico de Monterrey\n",
    "\n",
    "* Dr. Iván Olmos Pineda\n",
    "* Mtra. Verónica Sandra Guzmán de Valle\n",
    "* Mtro. Alberto Daniel Salinas Montemayor\n",
    "\n",
    "**Actividad 4** - \n",
    "Métricas de calidad de resultados\n",
    "\n",
    "**Fecha de entrega** - \n",
    "8 de junio del 2025\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c4a7c",
   "metadata": {},
   "source": [
    "**Presenta**\n",
    "\n",
    "|  NOMBRE COMPLETO                        |     MATRÍCULA     |\n",
    "| :-------------------------------------: |:-----------------:|\n",
    "| Alejandro Díaz Villagómez               |  A01276769        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62f588",
   "metadata": {},
   "source": [
    "# 0) Carga de datos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3760e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/alejandrodiazvillagomez/Desktop/Proyecto-Big-Data-PySpark/.venv/lib/python3.12/site-packages/pyspark'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from itertools import product\n",
    "from os import path\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "492e017b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/01 20:07:43 WARN Utils: Your hostname, Alejandros-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.100.202 instead (on interface en0)\n",
      "25/06/01 20:07:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/01 20:07:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.100.202:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x105fccdd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a140f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileManager():\n",
    "    @staticmethod\n",
    "    def open_csv_file(file_path : str):\n",
    "        \"\"\"\n",
    "        This method opens a csv file with pyspark\n",
    "        \"\"\"\n",
    "        csv_df = spark.read.csv(\n",
    "            file_path,\n",
    "            header=True,\n",
    "            inferSchema=True,\n",
    "            multiLine=True,\n",
    "            escape=\"\\\"\",\n",
    "            quote=\"\\\"\"\n",
    "        )\n",
    "\n",
    "        # csv_df.show(truncate=20)\n",
    "\n",
    "        return csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eedc112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandrodiazvillagomez/Desktop/Proyecto-Big-Data-PySpark/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/alejandrodiazvillagomez/.cache/kagglehub/datasets/machharavikiran/amazon-reviews/versions/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>22873041</td>\n",
       "      <td>R3ARRMDEGED8RD</td>\n",
       "      <td>B00KJWQIIC</td>\n",
       "      <td>335625766</td>\n",
       "      <td>Plemo 14-Inch Laptop Sleeve Case Waterproof Fa...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Pleasantly surprised</td>\n",
       "      <td>I was very surprised at the high quality of th...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>30088427</td>\n",
       "      <td>RQ28TSA020Y6J</td>\n",
       "      <td>B013ALA9LA</td>\n",
       "      <td>671157305</td>\n",
       "      <td>TP-Link OnHub AC1900 Wireless Wi-Fi Router</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>OnHub is a pretty no nonsense type router that...</td>\n",
       "      <td>I am a Google employee and had to chance to us...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>20329786</td>\n",
       "      <td>RUXJRZCT6953M</td>\n",
       "      <td>B00PML2GQ8</td>\n",
       "      <td>982036237</td>\n",
       "      <td>AmazonBasics USB 3.0 A Male to A Male Cable - ...</td>\n",
       "      <td>PC</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>None of them worked.  No functionality at all.</td>\n",
       "      <td>Bought cables in 3ft, 6ft and 9ft.  NONE of th...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>14215710</td>\n",
       "      <td>R7EO0UO6BPB71</td>\n",
       "      <td>B001NS0OZ4</td>\n",
       "      <td>576587596</td>\n",
       "      <td>Transcend P8 15-in-1 USB 2.0 Flash Memory Card...</td>\n",
       "      <td>PC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>just keep searching.</td>\n",
       "      <td>nope, cheap and slow</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>38264512</td>\n",
       "      <td>R39NJY2YJ1JFSV</td>\n",
       "      <td>B00AQMTND2</td>\n",
       "      <td>964759214</td>\n",
       "      <td>Aleratec SATA Data Cable 2.0 20in Serial ATA S...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Excellent! Great value and does the job.</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US</td>\n",
       "      <td>30548466</td>\n",
       "      <td>R31SR7REWNX7CF</td>\n",
       "      <td>B00KX4TORI</td>\n",
       "      <td>170101802</td>\n",
       "      <td>Kingston Digital MobileLite G4 USB 3.0 Multi-F...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Good quality, works well and compact</td>\n",
       "      <td>Good quality,works well and compact size</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>US</td>\n",
       "      <td>589298</td>\n",
       "      <td>RVBP8I1R0CTZ8</td>\n",
       "      <td>B00P17WEMY</td>\n",
       "      <td>206124740</td>\n",
       "      <td>White 9 Inch Unlocked Dual Sim Card Phone Tabl...</td>\n",
       "      <td>PC</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>in fact this is third China good. Demn s***</td>\n",
       "      <td>This demn tablet is just a Real Chinese produc...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>US</td>\n",
       "      <td>49329488</td>\n",
       "      <td>R1QF6RS1PDLU18</td>\n",
       "      <td>B00TR05L9Y</td>\n",
       "      <td>778403103</td>\n",
       "      <td>Lenovo TAB2 A10 - 10.1\" 2-in-1 Tablet (1.5Ghz,...</td>\n",
       "      <td>PC</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Good</td>\n",
       "      <td>I am not sure I don't know if it is the tablet...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>US</td>\n",
       "      <td>50728290</td>\n",
       "      <td>R23AICGEDAJQL1</td>\n",
       "      <td>B0098Y77OG</td>\n",
       "      <td>177098042</td>\n",
       "      <td>Acer</td>\n",
       "      <td>PC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>You get what you pay for</td>\n",
       "      <td>After exactly 45 days, the screen went dark. P...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>US</td>\n",
       "      <td>37802374</td>\n",
       "      <td>R2EY3N4K9W19UP</td>\n",
       "      <td>B00IFYEYXC</td>\n",
       "      <td>602496520</td>\n",
       "      <td>AzureWave Broadcom BCM94352HMB 802.11/ac/867Mb...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great for Windows 7 Laptop!</td>\n",
       "      <td>Replaced my Intel Centrino 2230 with the BCM94...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     22873041  R3ARRMDEGED8RD  B00KJWQIIC       335625766   \n",
       "1          US     30088427   RQ28TSA020Y6J  B013ALA9LA       671157305   \n",
       "2          US     20329786   RUXJRZCT6953M  B00PML2GQ8       982036237   \n",
       "3          US     14215710   R7EO0UO6BPB71  B001NS0OZ4       576587596   \n",
       "4          US     38264512  R39NJY2YJ1JFSV  B00AQMTND2       964759214   \n",
       "5          US     30548466  R31SR7REWNX7CF  B00KX4TORI       170101802   \n",
       "6          US       589298   RVBP8I1R0CTZ8  B00P17WEMY       206124740   \n",
       "7          US     49329488  R1QF6RS1PDLU18  B00TR05L9Y       778403103   \n",
       "8          US     50728290  R23AICGEDAJQL1  B0098Y77OG       177098042   \n",
       "9          US     37802374  R2EY3N4K9W19UP  B00IFYEYXC       602496520   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  Plemo 14-Inch Laptop Sleeve Case Waterproof Fa...               PC   \n",
       "1         TP-Link OnHub AC1900 Wireless Wi-Fi Router               PC   \n",
       "2  AmazonBasics USB 3.0 A Male to A Male Cable - ...               PC   \n",
       "3  Transcend P8 15-in-1 USB 2.0 Flash Memory Card...               PC   \n",
       "4  Aleratec SATA Data Cable 2.0 20in Serial ATA S...               PC   \n",
       "5  Kingston Digital MobileLite G4 USB 3.0 Multi-F...               PC   \n",
       "6  White 9 Inch Unlocked Dual Sim Card Phone Tabl...               PC   \n",
       "7  Lenovo TAB2 A10 - 10.1\" 2-in-1 Tablet (1.5Ghz,...               PC   \n",
       "8                                               Acer               PC   \n",
       "9  AzureWave Broadcom BCM94352HMB 802.11/ac/867Mb...               PC   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              0            0    N                 Y   \n",
       "1            5             24           31    N                 N   \n",
       "2            1              2            2    N                 N   \n",
       "3            1              0            0    N                 Y   \n",
       "4            5              0            0    N                 Y   \n",
       "5            5              0            0    N                 Y   \n",
       "6            3              1            2    N                 Y   \n",
       "7            4              1            1    N                 Y   \n",
       "8            1              0            0    N                 Y   \n",
       "9            5              3            4    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                               Pleasantly surprised   \n",
       "1  OnHub is a pretty no nonsense type router that...   \n",
       "2     None of them worked.  No functionality at all.   \n",
       "3                               just keep searching.   \n",
       "4                                         Five Stars   \n",
       "5               Good quality, works well and compact   \n",
       "6        in fact this is third China good. Demn s***   \n",
       "7                                               Good   \n",
       "8                           You get what you pay for   \n",
       "9                        Great for Windows 7 Laptop!   \n",
       "\n",
       "                                         review_body review_date  sentiment  \n",
       "0  I was very surprised at the high quality of th...  2015-08-31          1  \n",
       "1  I am a Google employee and had to chance to us...  2015-08-31          1  \n",
       "2  Bought cables in 3ft, 6ft and 9ft.  NONE of th...  2015-08-31          0  \n",
       "3                               nope, cheap and slow  2015-08-31          0  \n",
       "4           Excellent! Great value and does the job.  2015-08-31          1  \n",
       "5           Good quality,works well and compact size  2015-08-31          1  \n",
       "6  This demn tablet is just a Real Chinese produc...  2015-08-31          0  \n",
       "7  I am not sure I don't know if it is the tablet...  2015-08-31          1  \n",
       "8  After exactly 45 days, the screen went dark. P...  2015-08-31          0  \n",
       "9  Replaced my Intel Centrino 2230 with the BCM94...  2015-08-31          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "FILE_PATH = kagglehub.dataset_download(\"machharavikiran/amazon-reviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", FILE_PATH)\n",
    "\n",
    "df_reviews = FileManager.open_csv_file(FILE_PATH)\n",
    "df_reviews.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0862e765",
   "metadata": {},
   "source": [
    "# 1) Construcción de la muestra M\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a9e5e",
   "metadata": {},
   "source": [
    "* **Instrucciones**: Construir una muestra `𝑀` que sea representativa de la población `𝑃` (a partir del dataset que recolectaste desde el inicio del curso). Tomando como base el conocimiento adquirido en la *Actividad 3 del Módulo 4*, generarás particiones `𝑀𝑖` de `𝑀`, donde cada `𝑀𝑖` cumple con los criterios definidos por las variables de caracterización que identificaste previamente (`𝑀` será igual a la unión de todos los `𝑀𝑖`). Para esta actividad, y a diferencia del paso previo, se deberá de tener especial cuidado para determinar el número de instancias que deberá contender cada partición `𝑀𝑖` a generar, de tal forma que no se inyecte ningún tipo de sesgo que pueda alterar la calidad de los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044d45bb",
   "metadata": {},
   "source": [
    "## 1.1) Analizar la Distribución de las Variables Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2308c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Análisis de la Distribución de la Población (df_reviews) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de las combinaciones en la población:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>vine</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>823420</td>\n",
       "      <td>11.922281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>36069</td>\n",
       "      <td>0.522242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>6046916</td>\n",
       "      <td>87.553174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>159</td>\n",
       "      <td>0.002302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  verified_purchase vine    count  percentage\n",
       "0                 N    N   823420   11.922281\n",
       "1                 N    Y    36069    0.522242\n",
       "2                 Y    N  6046916   87.553174\n",
       "3                 Y    Y      159    0.002302"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = [\"verified_purchase\", \"vine\"]\n",
    "\n",
    "print(\"--- Análisis de la Distribución de la Población (df_reviews) ---\")\n",
    "\n",
    "# Contar las ocurrencias de cada combinación de las variables categóricas\n",
    "population_distribution = df_reviews.groupBy(categorical_cols).count()\n",
    "population_distribution = population_distribution.withColumn(\n",
    "    \"percentage\", (F.col(\"count\") / df_reviews.count()) * 100\n",
    ").orderBy(categorical_cols)\n",
    "\n",
    "print(\"\\nDistribución de las combinaciones en la población:\")\n",
    "population_distribution.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe64b1",
   "metadata": {},
   "source": [
    "En esta primera etapa del proceso, se realiza un análisis exploratorio de la distribución de la población original (`df_reviews`) con base en dos variables categóricas seleccionadas: `verified_purchase` y `vine`. A diferencia del entregable previo, en esta ocasión se decidió excluir la variable `star_rating` del conjunto de variables de caracterización. Esta decisión responde a un hallazgo clave derivado del análisis supervisado anterior, donde se identificó que `star_rating` guarda una correlación directa y significativa con la variable objetivo `sentiment`, lo cual podría introducir un sesgo indeseado en la construcción de la muestra representativa. Mantener únicamente variables neutras y no directamente relacionadas con la etiqueta de salida garantiza una segmentación más imparcial y metodológicamente sólida.\n",
    "\n",
    "El análisis de distribución revela que la gran mayoría de las observaciones corresponde a reseñas verificadas (`verified_purchase = Y`) y no asociadas al programa Vine (`vine = N`), representando aproximadamente el 87.55% del total. Otras combinaciones, como reseñas no verificadas (`verified_purchase = N`) o aquellas marcadas como parte del programa Vine (`vine = Y`), conforman proporciones mucho menores. Este paso es fundamental ya que permite identificar las proporciones reales de cada estrato dentro de la población y constituye la base para una posterior selección muestral proporcional, asegurando que la muestra `𝑀` sea verdaderamente representativa de la población `𝑃`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1f8e98",
   "metadata": {},
   "source": [
    "## 1.2) Determinar el Tamaño de la Muestra (M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39413582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de registros en la población: 6906564\n",
      "Tamaño de la muestra deseado (aprox. 10.0%): 690656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Vamos a definir un tamaño de muestra. Para este ejemplo, usemos el 10% del total de registros.\n",
    "# Puedes ajustar este valor según tus necesidades y recursos.\n",
    "sample_fraction = 0.1\n",
    "total_population_count = df_reviews.count()\n",
    "sample_size = int(total_population_count * sample_fraction)\n",
    "\n",
    "print(f\"Total de registros en la población: {total_population_count}\")\n",
    "print(f\"Tamaño de la muestra deseado (aprox. {sample_fraction*100}%): {sample_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90767488",
   "metadata": {},
   "source": [
    "En esta segunda etapa se define el tamaño de la muestra `𝑀` que será extraída de la población `𝑃`, con el propósito de construir un subconjunto representativo que preserve la estructura y diversidad de los datos originales. Para este fin, se estableció un valor de muestreo equivalente al **10% del total de registros disponibles**. Esta proporción fue seleccionada con base en criterios metodológicos y computacionales, considerando tanto la escala del conjunto de datos como los objetivos del análisis posterior.\n",
    "\n",
    "Desde el punto de vista estadístico, una fracción del 10% resulta suficiente para capturar patrones relevantes y garantizar una adecuada representación de las combinaciones categóricas identificadas previamente, incluso en escenarios donde algunos estratos presentan baja frecuencia relativa. Además, esta decisión permite mantener un equilibrio adecuado entre la fidelidad de la muestra y la eficiencia computacional, particularmente importante en contextos de Big Data donde el volumen de información puede impactar significativamente el rendimiento de las operaciones.\n",
    "\n",
    "Al delimitar explícitamente el tamaño de la muestra, se establece un marco cuantitativo claro que orienta la distribución proporcional de las instancias en cada segmento, evitando sesgos y distorsiones en las etapas siguientes del análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e4f20",
   "metadata": {},
   "source": [
    "## 1.3) Calcular el Número de Instancias por Partición (Mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c94d7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Distribución Deseada de la Muestra y Conteo por Partición ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('N', 'N'): 82342.0,\n",
       " ('N', 'Y'): 3607.0,\n",
       " ('Y', 'N'): 604691.0,\n",
       " ('Y', 'Y'): 16.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular el número de instancias para cada combinación en la muestra\n",
    "print(\"--- Distribución Deseada de la Muestra y Conteo por Partición ---\")\n",
    "\n",
    "sample_distribution = population_distribution.withColumn(\n",
    "    \"sample_count\", F.round(F.col(\"percentage\") * sample_size / 100)\n",
    ")\n",
    "sample_distribution.toPandas() # Muestra el conteo deseado para cada partición en la muestra\n",
    "\n",
    "# Convertir a un diccionario para facilitar la selección de la muestra estratificada\n",
    "sample_counts_dict = {\n",
    "    tuple(row[col] for col in categorical_cols): row[\"sample_count\"]\n",
    "    for row in sample_distribution.collect()\n",
    "}\n",
    "sample_counts_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfecead0",
   "metadata": {},
   "source": [
    "Se procede a determinar la distribución deseada de la muestra representativa `𝑀`, en función de las proporciones previamente observadas en la población `𝑃` respecto a las variables categóricas seleccionadas: `verified_purchase` y `vine`. Para ello, se calcula la cantidad de instancias que cada combinación posible de estas variables deberá contener dentro de la muestra, con base en su porcentaje de representación original y el tamaño total previamente definido para `𝑀` (10% del total poblacional).\n",
    "\n",
    "Este procedimiento tiene como objetivo preservar la estructura interna de la población, garantizando que la muestra conserve de manera proporcional la diversidad y distribución de los distintos perfiles existentes en los datos. En otras palabras, se busca construir una muestra estratificada que refleje fielmente la composición original de los datos en términos de las variables de caracterización elegidas.\n",
    "\n",
    "Los resultados obtenidos muestran que la combinación más frecuente es `('Y', 'N')`, correspondiente a registros de usuarios que realizaron una compra verificada y que no pertenecen al programa Vine, con una representación esperada de aproximadamente 604,691 registros dentro de la muestra. Le siguen `('N', 'N')` con 82,342 registros, `('N', 'Y')` con 3,607, y `('Y', 'Y')` con solo 16 registros. Esta distribución, aunque desigual, es consistente con la frecuencia real de ocurrencia en la población y será la base para extraer de forma estratificada los registros que compondrán la muestra final `𝑀`.\n",
    "\n",
    "Este paso es esencial para asegurar que las particiones `𝑀𝑖`, construidas posteriormente a partir de `𝑀`, sean equilibradas, realistas y libres de sesgos de representación, lo que a su vez fortalece la validez estadística de cualquier análisis futuro derivado del conjunto muestral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a943b398",
   "metadata": {},
   "source": [
    "# 1.4) Generar la Muestra (M) de forma estratificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec531515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generando la Muestra (M) de forma Estratificada ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros en la muestra final (M): 691829\n",
      "Muestra (M) generada. Mostrando las primeras 5 filas:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>112405</td>\n",
       "      <td>RKP98DQX0VTFZ</td>\n",
       "      <td>B00T91YABQ</td>\n",
       "      <td>541159143</td>\n",
       "      <td>Polare Thick Full Grain Leather Shoulder Brief...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Awesome Bag!</td>\n",
       "      <td>I bought this bag looking for a briefcase that...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>46558847</td>\n",
       "      <td>R3MSK0V0TDL01L</td>\n",
       "      <td>B00TKFDFW6</td>\n",
       "      <td>701421383</td>\n",
       "      <td>CybertronPC SOKOM-I Gaming Desktop - AMD FX-63...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>It's a Monster Machine</td>\n",
       "      <td>I bought a slightly modified version of this C...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>19852854</td>\n",
       "      <td>RM6KESMRIY1UQ</td>\n",
       "      <td>B00746W9F2</td>\n",
       "      <td>41875278</td>\n",
       "      <td>Apple iPad mini</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>very good price!</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>13443121</td>\n",
       "      <td>R2A948UZQGFZHO</td>\n",
       "      <td>B00KQE99C0</td>\n",
       "      <td>348236562</td>\n",
       "      <td>Standing Protective Case for Fire HD 7 (4th Ge...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Love it, it protects the screen and I love the...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>107911</td>\n",
       "      <td>RS1QTAUB8FJI0</td>\n",
       "      <td>B00JQZJ75E</td>\n",
       "      <td>937857628</td>\n",
       "      <td>iXCC Silicon Case Cover for Apple iPad Mini</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Nice case for the money. It is comfortable to ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US       112405   RKP98DQX0VTFZ  B00T91YABQ       541159143   \n",
       "1          US     46558847  R3MSK0V0TDL01L  B00TKFDFW6       701421383   \n",
       "2          US     19852854   RM6KESMRIY1UQ  B00746W9F2        41875278   \n",
       "3          US     13443121  R2A948UZQGFZHO  B00KQE99C0       348236562   \n",
       "4          US       107911   RS1QTAUB8FJI0  B00JQZJ75E       937857628   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  Polare Thick Full Grain Leather Shoulder Brief...               PC   \n",
       "1  CybertronPC SOKOM-I Gaming Desktop - AMD FX-63...               PC   \n",
       "2                                    Apple iPad mini               PC   \n",
       "3  Standing Protective Case for Fire HD 7 (4th Ge...               PC   \n",
       "4        iXCC Silicon Case Cover for Apple iPad Mini               PC   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              1            3    N                 N   \n",
       "1            5              1            1    N                 N   \n",
       "2            5              0            0    N                 N   \n",
       "3            5              0            0    N                 N   \n",
       "4            5              0            0    N                 N   \n",
       "\n",
       "          review_headline                                        review_body  \\\n",
       "0            Awesome Bag!  I bought this bag looking for a briefcase that...   \n",
       "1  It's a Monster Machine  I bought a slightly modified version of this C...   \n",
       "2              Five Stars                                   very good price!   \n",
       "3              Five Stars  Love it, it protects the screen and I love the...   \n",
       "4                 5 stars  Nice case for the money. It is comfortable to ...   \n",
       "\n",
       "  review_date  sentiment  \n",
       "0  2015-08-31          1  \n",
       "1  2015-08-31          1  \n",
       "2  2015-08-31          1  \n",
       "3  2015-08-31          1  \n",
       "4  2015-08-31          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para asegurar la representatividad, realizaremos un muestreo estratificado.\n",
    "# Esto implica muestrear cada \"estrato\" (combinación de categorías) por separado para asegurar las proporciones deseadas.\n",
    "print(\"--- Generando la Muestra (M) de forma Estratificada ---\")\n",
    "\n",
    "sample_df = spark.createDataFrame([], df_reviews.schema) # DataFrame vacío para la muestra\n",
    "\n",
    "for combo_values, count_needed in sample_counts_dict.items():\n",
    "    if count_needed > 0:\n",
    "        filter_condition = None\n",
    "        for i, col_name in enumerate(categorical_cols):\n",
    "            if filter_condition is None:\n",
    "                filter_condition = (F.col(col_name) == combo_values[i])\n",
    "            else:\n",
    "                filter_condition = filter_condition & (F.col(col_name) == combo_values[i])\n",
    "\n",
    "        # Seleccionar las filas para el estrato actual\n",
    "        stratum_df = df_reviews.filter(filter_condition)\n",
    "\n",
    "        # Si el estrato tiene menos registros de los que necesitamos, tomamos todos.\n",
    "        # Si tiene más, tomamos una muestra aleatoria del tamaño deseado.\n",
    "        current_stratum_count = stratum_df.count()\n",
    "        if current_stratum_count > 0:\n",
    "            if count_needed < current_stratum_count:\n",
    "                # Tomamos una muestra aleatoria del tamaño deseado\n",
    "                fraction = count_needed / current_stratum_count\n",
    "                sampled_stratum = stratum_df.sample(withReplacement=False, fraction=fraction, seed=42)\n",
    "            else:\n",
    "                # Si no hay suficientes registros en el estrato, tomamos todos los disponibles\n",
    "                sampled_stratum = stratum_df\n",
    "\n",
    "            # Unir al DataFrame de la muestra principal\n",
    "            sample_df = sample_df.unionAll(sampled_stratum)\n",
    "\n",
    "print(f\"Número de registros en la muestra final (M): {sample_df.count()}\")\n",
    "print(\"Muestra (M) generada. Mostrando las primeras 5 filas:\")\n",
    "sample_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649893ba",
   "metadata": {},
   "source": [
    "En este paso se lleva a cabo la generación efectiva de la muestra `𝑀` mediante un proceso de **muestreo estratificado**. A diferencia de un muestreo aleatorio simple, el enfoque estratificado garantiza que cada subconjunto de interés (en este caso, definido por las combinaciones de las variables categóricas `verified_purchase` y `vine`) esté adecuadamente representado en la muestra final, en proporciones equivalentes a las observadas en la población `𝑃`.\n",
    "\n",
    "Para ello, se recorre cada combinación posible de valores previamente identificada y se extrae un subconjunto de registros desde el conjunto poblacional, aplicando una lógica condicional que asegura tanto la proporcionalidad deseada como la eficiencia computacional. En particular, cuando un estrato contiene más registros que los requeridos, se realiza un muestreo aleatorio sin reemplazo proporcional a su tamaño; en contraste, si el estrato es más pequeño que la cantidad esperada, se conservan todos los registros disponibles. Este tratamiento dual permite construir una muestra robusta, incluso en presencia de categorías minoritarias o desbalanceadas.\n",
    "\n",
    "El resultado final fue la obtención de una muestra `𝑀` con 691,829 registros, cifra levemente superior al valor estimado originalmente (690,656) debido a efectos de redondeo y disponibilidad real de datos en algunos estratos. Esta ligera discrepancia es aceptable dentro de un marco de análisis exploratorio y no compromete la representatividad del conjunto, ya que la preservación de las proporciones entre categorías sigue siendo el criterio rector de la construcción muestral.\n",
    "\n",
    "Como se puede apreciar, este paso sienta las bases para asegurar que cualquier inferencia posterior, basada en la muestra `𝑀` o en sus particiones `𝑀𝑖`, no esté sesgada por sobre o subrepresentación de ciertos grupos, manteniendo la integridad metodológica del estudio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf18174",
   "metadata": {},
   "source": [
    "# 1.5) Crear las Particiones (Mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f080ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejemplo de partición M_i (verified_purchase='Y', vine='N'): 605672 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>37802374</td>\n",
       "      <td>R2EY3N4K9W19UP</td>\n",
       "      <td>B00IFYEYXC</td>\n",
       "      <td>602496520</td>\n",
       "      <td>AzureWave Broadcom BCM94352HMB 802.11/ac/867Mb...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great for Windows 7 Laptop!</td>\n",
       "      <td>Replaced my Intel Centrino 2230 with the BCM94...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>29333557</td>\n",
       "      <td>R3G4RT3EQ9RSY7</td>\n",
       "      <td>B00MA40W9I</td>\n",
       "      <td>535866197</td>\n",
       "      <td>Egoway® New Laptop Battery for Apple A1309 A12...</td>\n",
       "      <td>PC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Totally wasted $60 on this battery</td>\n",
       "      <td>Totally wasted $60 on this battery.  Didn't wo...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>16160990</td>\n",
       "      <td>RW9VR7UKL3E69</td>\n",
       "      <td>B00HPQ0H0K</td>\n",
       "      <td>176437370</td>\n",
       "      <td>ARCTIC S111 USB-Powered Portable Stereo Speake...</td>\n",
       "      <td>PC</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>tinny sounding</td>\n",
       "      <td>tinny weak sound</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>48701722</td>\n",
       "      <td>R7ER63LS7Q1O5</td>\n",
       "      <td>B00RXEWOAA</td>\n",
       "      <td>540891596</td>\n",
       "      <td>3.5\" USB External Floppy Disk Drive Portable 1...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Love it</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>19280847</td>\n",
       "      <td>RAYGOWHX4H47</td>\n",
       "      <td>B001J226JQ</td>\n",
       "      <td>210607495</td>\n",
       "      <td>Generic USB to 9-pin Serial Port Adapter</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>perfect</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     37802374  R2EY3N4K9W19UP  B00IFYEYXC       602496520   \n",
       "1          US     29333557  R3G4RT3EQ9RSY7  B00MA40W9I       535866197   \n",
       "2          US     16160990   RW9VR7UKL3E69  B00HPQ0H0K       176437370   \n",
       "3          US     48701722   R7ER63LS7Q1O5  B00RXEWOAA       540891596   \n",
       "4          US     19280847    RAYGOWHX4H47  B001J226JQ       210607495   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  AzureWave Broadcom BCM94352HMB 802.11/ac/867Mb...               PC   \n",
       "1  Egoway® New Laptop Battery for Apple A1309 A12...               PC   \n",
       "2  ARCTIC S111 USB-Powered Portable Stereo Speake...               PC   \n",
       "3  3.5\" USB External Floppy Disk Drive Portable 1...               PC   \n",
       "4           Generic USB to 9-pin Serial Port Adapter               PC   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              3            4    N                 Y   \n",
       "1            1              0            0    N                 Y   \n",
       "2            2              0            0    N                 Y   \n",
       "3            5              0            0    N                 Y   \n",
       "4            5              0            0    N                 Y   \n",
       "\n",
       "                      review_headline  \\\n",
       "0         Great for Windows 7 Laptop!   \n",
       "1  Totally wasted $60 on this battery   \n",
       "2                      tinny sounding   \n",
       "3                          Five Stars   \n",
       "4                          Five Stars   \n",
       "\n",
       "                                         review_body review_date  sentiment  \n",
       "0  Replaced my Intel Centrino 2230 with the BCM94...  2015-08-31          1  \n",
       "1  Totally wasted $60 on this battery.  Didn't wo...  2015-08-31          0  \n",
       "2                                   tinny weak sound  2015-08-31          0  \n",
       "3                                            Love it  2015-08-31          1  \n",
       "4                                            perfect  2015-08-31          1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Una vez que tenemos la muestra (sample_df), las particiones Mi son simplemente subconjuntos de esta \n",
    "# muestra basados en las combinaciones de las variables categóricas.\n",
    "# No es necesario almacenar cada Mi por separado si se va a trabajar con ellos de forma iterativa o agrupada. \n",
    "# Podemos simplemente agrupar por las variables categóricas cuando sea necesario.\n",
    "\n",
    "# Si se necesita acceder a una partición específica (Mi), se puede filtrar así:\n",
    "# Ejemplo: Partición para verified_purchase='Y', vine='N'\n",
    "mi_example = sample_df.filter((F.col(\"verified_purchase\") == \"Y\") &\n",
    "                              (F.col(\"vine\") == \"N\"))\n",
    "print(f\"\\nEjemplo de partición M_i (verified_purchase='Y', vine='N'): {mi_example.count()} registros\")\n",
    "mi_example.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a71c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creando las Particiones (Mi) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución REAL de las combinaciones en la Muestra (M):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>vine</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>82555</td>\n",
       "      <td>11.932862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>3583</td>\n",
       "      <td>0.517903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>605672</td>\n",
       "      <td>87.546489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>19</td>\n",
       "      <td>0.002746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  verified_purchase vine   count  percentage\n",
       "0                 N    N   82555   11.932862\n",
       "1                 N    Y    3583    0.517903\n",
       "2                 Y    N  605672   87.546489\n",
       "3                 Y    Y      19    0.002746"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"--- Creando las Particiones (Mi) ---\")\n",
    "\n",
    "# Verificamos que las proporciones se mantengan.\n",
    "sample_actual_distribution = sample_df.groupBy(categorical_cols).count()\n",
    "sample_actual_distribution = sample_actual_distribution.withColumn(\n",
    "    \"percentage\", (F.col(\"count\") / sample_df.count()) * 100\n",
    ").orderBy(categorical_cols)\n",
    "\n",
    "print(\"\\nDistribución REAL de las combinaciones en la Muestra (M):\")\n",
    "sample_actual_distribution.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0a2f29",
   "metadata": {},
   "source": [
    "En esta última fase del proceso se formaliza la creación de las particiones `𝑀𝑖`, definidas como subconjuntos disjuntos de la muestra `𝑀`, cuya segmentación responde a las combinaciones únicas de las variables categóricas seleccionadas. Dado que la muestra fue construida de manera estratificada en función de estas mismas variables, el agrupamiento por sus valores permite recuperar de forma directa cada una de las particiones sin necesidad de duplicar datos ni mantener estructuras adicionales.\n",
    "\n",
    "Este diseño no solo reduce el costo computacional, sino que ofrece flexibilidad metodológica: cada partición puede ser invocada y procesada dinámicamente según los requerimientos del análisis posterior. Por ejemplo, acceder a la partición \n",
    "`𝑀𝑖` correspondiente a `verified_purchase='Y'` y `vine='N'` permite trabajar exclusivamente con ese segmento de usuarios, aislando su comportamiento o características para estudios comparativos.\n",
    "\n",
    "Al verificar la distribución real de las combinaciones dentro de la muestra generada, se confirma que las proporciones han sido exitosamente conservadas. Las diferencias con respecto a los valores esperados son mínimas y atribuibles al redondeo y a la disponibilidad efectiva de registros dentro de ciertos estratos, sin comprometer la validez del enfoque.\n",
    "\n",
    "Este paso final garantiza que cada partición sea estadísticamente coherente con su representación en la población `𝑃`, eliminando riesgos de sesgo por subrepresentación o sobreajuste a grupos específicos. Este diseño habilita un análisis posterior más sólido y confiable, ajustado a los principios fundamentales de muestreo en escenarios de datos masivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95ee2a9",
   "metadata": {},
   "source": [
    "# 2) Construcción Train – Test\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaf68b3",
   "metadata": {},
   "source": [
    "* **Instrucciones**: Construcción del conjunto de entrenamiento y prueba. Para este paso se asume que `𝑀` = {`𝑀𝑖`: `𝑀𝑖` es una partición derivada de las variables de caracterización de la población} generada en el paso anterior. Para construir el conjunto de entrenamiento y prueba, se debe de calcular el porcentaje de división a usar, de tal forma que al dividir cada `𝑀𝑖` en un conjunto de entrenamiento (**𝑇𝑟𝑖**) y prueba (**𝑇𝑠𝑖**), no se inyecten sesgos que desvíen la probabilidad de ocurrencia de los patrones en cada nueva partición. Para ello, deberás de retomar la estrategia de muestreo propuesta en el paso 4 de la Actividad 3 del módulo 4. Se debe de cuidar que `𝑇𝑟𝑖 Ç 𝑇𝑠𝑖 = Æ`, además de que la unión de todas las particiones es igual a `𝑀`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7e8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(verified_purchase='N', vine='N'),\n",
       " Row(verified_purchase='N', vine='Y'),\n",
       " Row(verified_purchase='Y', vine='N'),\n",
       " Row(verified_purchase='Y', vine='Y')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir la proporción de división\n",
    "train_ratio = 0.7\n",
    "test_ratio = 1 - train_ratio\n",
    "seed = 42\n",
    "\n",
    "# Diccionarios para almacenar los conjuntos de entrenamiento y prueba por partición\n",
    "train_partitions = {} # { (verified_purchase, vine): DataFrame_Tri }\n",
    "test_partitions = {}  # { (verified_purchase, vine): DataFrame_Tsi }\n",
    "\n",
    "# Obtener todas las combinaciones únicas de las variables categóricas en la muestra (M)\n",
    "distinct_combinations = sample_df.select(categorical_cols).distinct().collect()\n",
    "distinct_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dad3db",
   "metadata": {},
   "source": [
    "La definición de una proporción de **70/30** para los conjuntos de entrenamiento y prueba responde a una práctica comúnmente aceptada en el ámbito del análisis de datos, ya que permite un equilibrio adecuado entre aprendizaje y validación. El uso de una semilla asegura la reproducibilidad del proceso, lo cual es fundamental en entornos experimentales. \n",
    "\n",
    "Por otro lado, la identificación explícita de las combinaciones presentes en la muestra evita errores asociados al redondeo o a la ausencia de estratos poco frecuentes, garantizando que la división se realice únicamente sobre particiones efectivamente representadas. El resultado obtenido (cuatro combinaciones únicas) confirma que la muestra mantiene la diversidad estructural necesaria para una segmentación estratificada válida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67936ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando partición Mi para: ('N', 'N')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTamaño de Mi: 82555 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTamaño de Tri: 57790 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTamaño de Tsi: 24765 registros\n",
      "\n",
      "Procesando partición Mi para: ('N', 'Y')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTamaño de Mi: 3583 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTamaño de Tri: 2455 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTamaño de Tsi: 1128 registros\n",
      "\n",
      "Procesando partición Mi para: ('Y', 'N')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTamaño de Mi: 605672 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTamaño de Tri: 424081 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTamaño de Tsi: 181591 registros\n",
      "\n",
      "Procesando partición Mi para: ('Y', 'Y')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTamaño de Mi: 19 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTamaño de Tri: 16 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 113:===================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTamaño de Tsi: 3 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Iterar sobre cada combinación para crear las particiones Mi y dividirlas\n",
    "for row in distinct_combinations:\n",
    "    combo_values = tuple(row[col] for col in categorical_cols)\n",
    "    print(f\"\\nProcesando partición Mi para: {combo_values}\")\n",
    "\n",
    "    # Aislamos la Partición Mi con apoyo de un filtro\n",
    "    filter_condition = None\n",
    "    for i, col_name in enumerate(categorical_cols):\n",
    "        if filter_condition is None:\n",
    "            filter_condition = (F.col(col_name) == combo_values[i])\n",
    "        else:\n",
    "            filter_condition = filter_condition & (F.col(col_name) == combo_values[i])\n",
    "\n",
    "    mi_df = sample_df.filter(filter_condition)\n",
    "    mi_count = mi_df.count()\n",
    "    print(f\"\\tTamaño de Mi: {mi_count} registros\")\n",
    "\n",
    "    # Dividimos la Partición Mi en Tri y Tsi\n",
    "    if mi_count > 0:\n",
    "        # randomSplit distribuye los datos aleatoriamente según las proporciones dadas\n",
    "        tri, tsi = mi_df.randomSplit([train_ratio, test_ratio], seed=seed)\n",
    "\n",
    "        # Almacenar las particiones resultantes\n",
    "        train_partitions[combo_values] = tri\n",
    "        test_partitions[combo_values] = tsi\n",
    "\n",
    "        print(f\"\\tTamaño de Tri: {tri.count()} registros\")\n",
    "        print(f\"\\tTamaño de Tsi: {tsi.count()} registros\")\n",
    "    else:\n",
    "        print(f\"\\tPartición Mi vacía. No se generarán Tri y Tsi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9b8f15",
   "metadata": {},
   "source": [
    "Con este código se hace la segmentación de la muestra representativa `𝑀` en subconjuntos de entrenamiento (`𝑇𝑟𝑖`) y prueba (`𝑇𝑠𝑖`) para cada una de las particiones `𝑀𝑖`, definidas previamente según las combinaciones únicas de las variables categóricas `verified_purchase` y `vine`. Esta estrategia garantiza que el proceso de entrenamiento y evaluación se lleve a cabo respetando la estructura interna de la población original, evitando así la introducción de sesgos derivados de una partición aleatoria no estratificada.\n",
    "\n",
    "El método empleado consiste en filtrar individualmente cada estrato `𝑀𝑖`, y aplicar la función `randomSplit` de PySpark para generar las correspondientes divisiones con una proporción **70/30**. Esto permite mantener la representatividad estadística dentro de cada combinación de atributos. Los resultados muestran que la distribución se ha respetado incluso en estratos de baja frecuencia, como el caso de la combinación `('Y', 'Y')`, donde se preservó una división razonable de 16 observaciones para entrenamiento y 3 para prueba.\n",
    "\n",
    "Esta partición controlada por estrato es especialmente valiosa en contextos donde existen desequilibrios severos entre categorías, ya que permite evaluar el desempeño del modelo de forma equitativa sobre todos los grupos relevantes. Además, al evitar el solapamiento entre `𝑇𝑟𝑖` y `𝑇𝑠𝑖`, se salvaguarda la independencia entre fases de entrenamiento y validación, requisito esencial para asegurar la robustez metodológica de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6c638cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verificación de las Condiciones ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de la muestra original (M): 691829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de la unión de todos los Tri y Tsi: 691829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 158:====================================================>(151 + 1) / 152]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡La condición de unión de particiones = M se cumple! Los conteos coinciden.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Verificamos las condiciones Tri Ç Tsi = Æ (no solapamiento) y la unión de todas las particiones = M\n",
    "# Cabe destcar que la condición Tri Ç Tsi = Æ se garantiza por la función `randomSplit` de Spark\n",
    "print(\"--- Verificación de las Condiciones ---\")\n",
    "\n",
    "# Unión de todos los Tri\n",
    "all_tri_union = spark.createDataFrame([], sample_df.schema)\n",
    "for combo, tri_df in train_partitions.items():\n",
    "    all_tri_union = all_tri_union.unionAll(tri_df)\n",
    "\n",
    "# Unión de todos los Tsi\n",
    "all_tsi_union = spark.createDataFrame([], sample_df.schema)\n",
    "for combo, tsi_df in test_partitions.items():\n",
    "    all_tsi_union = all_tsi_union.unionAll(tsi_df)\n",
    "\n",
    "# Unión de todos los Tri y Tsi\n",
    "# Usamos distinct para manejar posibles duplicados si no hay garantía estricta\n",
    "final_union_m = all_tri_union.unionAll(all_tsi_union).distinct()\n",
    "\n",
    "print(f\"Tamaño de la muestra original (M): {sample_df.count()}\")\n",
    "print(f\"Tamaño de la unión de todos los Tri y Tsi: {final_union_m.count()}\")\n",
    "\n",
    "# Si los conteos coinciden, la condición se cumple.\n",
    "if sample_df.count() == final_union_m.count():\n",
    "    print(\"¡La condición de unión de particiones = M se cumple! Los conteos coinciden.\")\n",
    "else:\n",
    "    print(\"Advertencia: Los conteos de la unión de particiones y la muestra M no coinciden.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f2cdd",
   "metadata": {},
   "source": [
    "Una vez realizadas las divisiones `𝑇𝑟𝑖` y `𝑇𝑠𝑖` correspondientes a cada partición `𝑀𝑖`, se llevó a cabo un proceso de verificación para confirmar que se cumplan dos condiciones fundamentales de integridad en el diseño experimental: la no superposición entre conjuntos de entrenamiento y prueba, es decir, `𝑇𝑟𝑖 ∩ 𝑇𝑠𝑖 = ∅`, y la exhaustividad de la muestra, es decir, que la unión de todas las particiones `𝑇𝑟𝑖 ∪ 𝑇𝑠𝑖` sea equivalente al conjunto original `𝑀`.\n",
    "\n",
    "La primera condición se garantiza implícitamente mediante el uso de la función `randomSplit` de PySpark, la cual está diseñada para generar subconjuntos mutuamente excluyentes a partir de un conjunto dado. En cuanto a la segunda condición, se construyó la unión de todas las particiones generadas y se aplicó una operación `distinct` para asegurar la unicidad de los registros. Al comparar el tamaño de esta unión con el total de registros de `𝑀`, se comprobó que ambos coinciden perfectamente, lo cual valida que no hubo pérdida ni duplicación de datos en el proceso de división."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a359f",
   "metadata": {},
   "source": [
    "# 3) Selección de métricas para medir calidad de resultados\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4970a38e",
   "metadata": {},
   "source": [
    "Con el objetivo de evaluar la calidad de los resultados obtenidos a partir de los modelos implementados, es fundamental seleccionar cuidadosamente las **métricas de desempeño**, considerando no solo la naturaleza del algoritmo (supervisado o no supervisado), sino también el volumen de datos procesado y las implicaciones computacionales de cada métrica en un entorno de Big Data.\n",
    "\n",
    "En el caso del modelo `RandomForestClassifier`, al tratarse de un enfoque supervisado orientado a la clasificación, se seleccionaron métricas estándar pero robustas que permiten evaluar el desempeño general y por clase del modelo. Específicamente, se consideran las siguientes: **accuracy, precision, recall y F1-score**, todas en su versión ponderada. Estas métricas permiten analizar no solo el número de aciertos globales, sino también la capacidad del modelo para distinguir correctamente entre las clases positivas y negativas, lo cual es especialmente relevante ante posibles desbalances en los datos. Adicionalmente, se utilizará la **matriz de confusión** como instrumento visual y cuantitativo que permite comprender la naturaleza de los errores cometidos (falsos positivos y falsos negativos), lo cual enriquece el análisis más allá de los valores promedio.\n",
    "\n",
    "Por otro lado, para el modelo `KMeans`, al ser un algoritmo no supervisado de agrupamiento, las métricas tradicionales de clasificación no resultan aplicables. En su lugar, se optó por la utilización del **Silhouette Score**, el cual mide qué tan similares son los puntos dentro de un mismo clúster en comparación con puntos de otros clústers. Esta métrica, además de ser ampliamente aceptada en tareas de agrupamiento, resulta computacionalmente viable en PySpark y permite inferir si el número de clústers seleccionado es coherente con la estructura de los datos. Complementariamente, se evaluará la **coherencia semántica de los clústers obtenidos mediante inspección manual y análisis de centroides promedio**, especialmente al comparar los resultados con la variable de salida conocida, lo que permite explorar la alineación entre los patrones descubiertos de manera no supervisada y las etiquetas originales.\n",
    "\n",
    "La selección de estas métricas responde a la doble necesidad de garantizar interpretabilidad y precisión en el análisis, al tiempo que se respeta la escalabilidad exigida por el tratamiento de grandes volúmenes de datos. La diversidad de enfoques implementados (supervisado y no supervisado) permite explorar diferentes dimensiones del comportamiento de los datos y establecer comparaciones que fortalecen la comprensión del problema y la calidad de las soluciones construidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37251ff",
   "metadata": {},
   "source": [
    "# 4) Entrenamiento de Modelos de Aprendizaje\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df7074",
   "metadata": {},
   "source": [
    "## 4.1) Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb0e238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Convertir las columnas categóricas a índices numéricos\n",
    "indexer_verified = StringIndexer(inputCol=\"verified_purchase\", outputCol=\"verified_purchase_index\", handleInvalid=\"skip\")\n",
    "indexer_vine = StringIndexer(inputCol=\"vine\", outputCol=\"vine_index\", handleInvalid=\"skip\")\n",
    "\n",
    "label_col = \"sentiment\"\n",
    "label_indexer = StringIndexer(inputCol=label_col, outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26245ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 167:===================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros después de eliminar nulos: 691829 (original: 691829)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Manejo de valores nulos \n",
    "initial_cols_to_check_for_nulls = [\n",
    "    \"helpful_votes\", \n",
    "    \"total_votes\", \n",
    "    \"verified_purchase\", \n",
    "    \"vine\", \n",
    "    \"sentiment\" # Label\n",
    "]\n",
    "\n",
    "sample_df_cleaned = sample_df.na.drop(subset=initial_cols_to_check_for_nulls)\n",
    "print(f\"Registros después de eliminar nulos: {sample_df_cleaned.count()} (original: {sample_df.count()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b229fa6",
   "metadata": {},
   "source": [
    "No se detectaron nulos, por lo que no se tiene que re-ejecutar el muestreo y la creación de particiones sobre sample_df_cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40564d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de las columnas que serán ensambladas en el vector de características\n",
    "feature_cols_for_assembler = [\n",
    "    \"helpful_votes\", \n",
    "    \"total_votes\", \n",
    "    \"verified_purchase_index\", \n",
    "    \"vine_index\"\n",
    "]\n",
    "\n",
    "vector_assembler = VectorAssembler(inputCols=feature_cols_for_assembler, outputCol=\"raw_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b781e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código para escalar las características\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"raw_features\", \n",
    "    outputCol=\"scaled_features\", \n",
    "    withStd=True, \n",
    "    withMean=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb306819",
   "metadata": {},
   "source": [
    "## 4.2) Entrenamiento y evaluación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "179d2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, ClusteringEvaluator\n",
    "\n",
    "# Diccionarios para almacenar los resultados de la evaluación\n",
    "rf_evaluation_results = {}\n",
    "kmeans_evaluation_results = {}\n",
    "\n",
    "# Definimos los modelos con hiperparámetros iniciales (se tunearán después)\n",
    "rf_model_instance = RandomForestClassifier(\n",
    "    featuresCol=\"scaled_features\", \n",
    "    labelCol=\"label\", \n",
    "    numTrees=20, \n",
    "    maxDepth=5, \n",
    "    seed=42\n",
    ")\n",
    "\n",
    "kmeans_model_instance = KMeans(\n",
    "    featuresCol=\"scaled_features\", \n",
    "    k=2, \n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Definimos los evaluadores\n",
    "rf_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "kmeans_evaluator = ClusteringEvaluator(\n",
    "    featuresCol=\"scaled_features\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"silhouette\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e147c203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando partición: ('N', 'N') (Train: 57790, Test: 24765)\n",
      "\tEntrenando RandomForestClassifier para ('N', 'N')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandomForest Metrics:\n",
      "\t\tAccuracy: 0.6609\n",
      "\t\tF1-Score (Weighted): 0.5271\n",
      "\t\tPrecision (Weighted): 0.6790\n",
      "\t\tRecall (Weighted): 0.6609\n",
      "\n",
      "\tMatriz de Confusión (RandomForest):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  prediction  count\n",
       "0    0.0         0.0  16348\n",
       "1    0.0         1.0      8\n",
       "2    1.0         0.0   8389\n",
       "3    1.0         1.0     20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntrenando KMeans para ('N', 'N')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKMeans Metrics:\n",
      "\t\tSilhouette Score: 0.9999\n",
      "\t\tWCSS: 50143.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando partición: ('N', 'Y') (Train: 2455, Test: 1128)\n",
      "\tEntrenando RandomForestClassifier para ('N', 'Y')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandomForest Metrics:\n",
      "\t\tAccuracy: 0.7757\n",
      "\t\tF1-Score (Weighted): 0.6777\n",
      "\t\tPrecision (Weighted): 0.6017\n",
      "\t\tRecall (Weighted): 0.7757\n",
      "\n",
      "\tMatriz de Confusión (RandomForest):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  prediction  count\n",
       "0    0.0         0.0    875\n",
       "1    1.0         0.0    253"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntrenando KMeans para ('N', 'Y')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKMeans Metrics:\n",
      "\t\tSilhouette Score: 0.9992\n",
      "\t\tWCSS: 1383.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando partición: ('Y', 'N') (Train: 424081, Test: 181591)\n",
      "\tEntrenando RandomForestClassifier para ('Y', 'N')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandomForest Metrics:\n",
      "\t\tAccuracy: 0.7788\n",
      "\t\tF1-Score (Weighted): 0.6820\n",
      "\t\tPrecision (Weighted): 0.6065\n",
      "\t\tRecall (Weighted): 0.7788\n",
      "\n",
      "\tMatriz de Confusión (RandomForest):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  prediction   count\n",
       "0    0.0         0.0  141424\n",
       "1    1.0         0.0   40167"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntrenando KMeans para ('Y', 'N')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKMeans Metrics:\n",
      "\t\tSilhouette Score: 1.0000\n",
      "\t\tWCSS: 103277.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando partición: ('Y', 'Y') (Train: 16, Test: 3)\n",
      "\tEntrenando RandomForestClassifier para ('Y', 'Y')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandomForest Metrics:\n",
      "\t\tAccuracy: 1.0000\n",
      "\t\tF1-Score (Weighted): 1.0000\n",
      "\t\tPrecision (Weighted): 1.0000\n",
      "\t\tRecall (Weighted): 1.0000\n",
      "\n",
      "\tMatriz de Confusión (RandomForest):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  prediction  count\n",
       "0    0.0         0.0      3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEntrenando KMeans para ('Y', 'Y')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 545:===================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKMeans Metrics:\n",
      "\t\tSilhouette Score: 0.9059\n",
      "\t\tWCSS: 5.15\n",
      "\n",
      "--- Entrenamiento y evaluación por partición completados. ---\n",
      "Resultados de RandomForest: {('N', 'N'): {'accuracy': 0.6609327680193822, 'f1_score': 0.5271011415626842, 'weighted_precision': 0.6790089713851148, 'weighted_recall': 0.6609327680193823, 'confusion_matrix': [{'label': 0.0, 'prediction': 0.0, 'count': 16348}, {'label': 0.0, 'prediction': 1.0, 'count': 8}, {'label': 1.0, 'prediction': 0.0, 'count': 8389}, {'label': 1.0, 'prediction': 1.0, 'count': 20}]}, ('N', 'Y'): {'accuracy': 0.775709219858156, 'f1_score': 0.6777289739150141, 'weighted_precision': 0.601724793772949, 'weighted_recall': 0.775709219858156, 'confusion_matrix': [{'label': 0.0, 'prediction': 0.0, 'count': 875}, {'label': 1.0, 'prediction': 0.0, 'count': 253}]}, ('Y', 'N'): {'accuracy': 0.7788051169936836, 'f1_score': 0.6819604963590836, 'weighted_precision': 0.6065374102555452, 'weighted_recall': 0.7788051169936836, 'confusion_matrix': [{'label': 0.0, 'prediction': 0.0, 'count': 141424}, {'label': 1.0, 'prediction': 0.0, 'count': 40167}]}, ('Y', 'Y'): {'accuracy': 1.0, 'f1_score': 1.0, 'weighted_precision': 1.0, 'weighted_recall': 1.0, 'confusion_matrix': [{'label': 0.0, 'prediction': 0.0, 'count': 3}]}}\n",
      "Resultados de KMeans: {('N', 'N'): {'silhouette_score': 0.9999486445701851, 'wcss': 50143.414153751924}, ('N', 'Y'): {'silhouette_score': 0.9992155633311729, 'wcss': 1383.1922442937162}, ('Y', 'N'): {'silhouette_score': 0.9999977190848507, 'wcss': 103277.30536698787}, ('Y', 'Y'): {'silhouette_score': 0.905864022247715, 'wcss': 5.149146096746269}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Bucle para entrenar y evaluar en cada partición\n",
    "for combo_values, tri_df in train_partitions.items():\n",
    "    tsi_df = test_partitions[combo_values]\n",
    "    print(f\"\\nProcesando partición: {combo_values} (Train: {tri_df.count()}, Test: {tsi_df.count()})\")\n",
    "\n",
    "    # --- RandomForestClassifier ---\n",
    "    print(f\"\\tEntrenando RandomForestClassifier para {combo_values}...\")\n",
    "    rf_pipeline = Pipeline(stages=[\n",
    "        indexer_verified,\n",
    "        indexer_vine,\n",
    "        vector_assembler,\n",
    "        scaler,\n",
    "        label_indexer,\n",
    "        rf_model_instance\n",
    "    ])\n",
    "\n",
    "    # Ejecutar pipeline de RF\n",
    "    rf_fitted_pipeline = rf_pipeline.fit(tri_df)\n",
    "\n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    rf_predictions = rf_fitted_pipeline.transform(tsi_df)\n",
    "\n",
    "    # Evaluar RandomForestClassifier\n",
    "    accuracy = rf_evaluator.evaluate(rf_predictions, {rf_evaluator.metricName: \"accuracy\"})\n",
    "    f1_score = rf_evaluator.evaluate(rf_predictions, {rf_evaluator.metricName: \"f1\"})\n",
    "    weighted_precision = rf_evaluator.evaluate(rf_predictions, {rf_evaluator.metricName: \"weightedPrecision\"})\n",
    "    weighted_recall = rf_evaluator.evaluate(rf_predictions, {rf_evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "    print(f\"\\tRandomForest Metrics:\")\n",
    "    print(f\"\\t\\tAccuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\t\\tF1-Score (Weighted): {f1_score:.4f}\")\n",
    "    print(f\"\\t\\tPrecision (Weighted): {weighted_precision:.4f}\")\n",
    "    print(f\"\\t\\tRecall (Weighted): {weighted_recall:.4f}\")\n",
    "\n",
    "    # Matriz de Confusión\n",
    "    print(\"\\n\\tMatriz de Confusión (RandomForest):\")\n",
    "    confusion_pdf = rf_predictions.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\").toPandas()\n",
    "    display(confusion_pdf)\n",
    "\n",
    "    rf_evaluation_results[combo_values] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"weighted_precision\": weighted_precision,\n",
    "        \"weighted_recall\": weighted_recall,\n",
    "        \"confusion_matrix\": confusion_pdf.to_dict('records') # Almacenar como lista de dicts\n",
    "    }\n",
    "\n",
    "    # --- KMeans ---\n",
    "    print(f\"\\tEntrenando KMeans para {combo_values}...\")\n",
    "    kmeans_pipeline = Pipeline(stages=[\n",
    "        indexer_verified,\n",
    "        indexer_vine,\n",
    "        vector_assembler,\n",
    "        scaler,\n",
    "        kmeans_model_instance\n",
    "    ])\n",
    "\n",
    "    # Ejecutar pipeline de KMeans\n",
    "    kmeans_fitted_pipeline = kmeans_pipeline.fit(tri_df)\n",
    "\n",
    "    # Realizar predicciones de clústeres en la misma partición de entrenamiento para evaluación\n",
    "    # (KMeans es no supervisado, evaluamos la estructura de los clústeres en los datos que usó para aprender)\n",
    "    kmeans_predictions = kmeans_fitted_pipeline.transform(tri_df)\n",
    "\n",
    "    # Evaluar KMeans\n",
    "    silhouette_score = kmeans_evaluator.evaluate(kmeans_predictions)\n",
    "    # WCSS (Within-Cluster Sum of Squared Errors) se obtiene del modelo KMeans ajustado\n",
    "    wcss = kmeans_fitted_pipeline.stages[-1].summary.trainingCost\n",
    "\n",
    "    print(f\"\\tKMeans Metrics:\")\n",
    "    print(f\"\\t\\tSilhouette Score: {silhouette_score:.4f}\")\n",
    "    print(f\"\\t\\tWCSS: {wcss:.2f}\")\n",
    "\n",
    "    kmeans_evaluation_results[combo_values] = {\n",
    "        \"silhouette_score\": silhouette_score,\n",
    "        \"wcss\": wcss\n",
    "    }\n",
    "\n",
    "print(\"\\n--- Entrenamiento y evaluación por partición completados. ---\")\n",
    "print(\"Resultados de RandomForest:\", rf_evaluation_results)\n",
    "print(\"Resultados de KMeans:\", kmeans_evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52ca23",
   "metadata": {},
   "source": [
    "## 4.3) Ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Seleccionamos una partición representativa para el ajuste de hiperparámetros:\n",
    "# Para este ejemplo, tomaremos la primera partición de entrenamiento disponible.\n",
    "if not train_partitions:\n",
    "    print(\"No hay particiones de entrenamiento disponibles para el ajuste de hiperparámetros.\")\n",
    "else:\n",
    "    first_combo_key = list(train_partitions.keys())[0]\n",
    "    tuning_data_df = train_partitions[first_combo_key]\n",
    "    print(f\"Realizando ajuste de hiperparámetros en la partición: {first_combo_key} (Tamaño: {tuning_data_df.count()})\")\n",
    "\n",
    "    print(\"\\n  Ajustando Hiperparámetros para RandomForestClassifier...\")\n",
    "\n",
    "    # Instanciamos un nuevo RandomForestClassifier (sin numTrees y maxDepth específicos aquí, se definirán en ParamGrid)\n",
    "    rf_tune_model_instance = RandomForestClassifier(\n",
    "        featuresCol=\"scaled_features\", \n",
    "        labelCol=\"label\", \n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # Reconstruimos el pipeline de RF para tuning, usando la instancia `rf_tune_model_instance`\n",
    "    rf_tune_pipeline = Pipeline(stages=[\n",
    "        indexer_verified,\n",
    "        indexer_vine,\n",
    "        vector_assembler,\n",
    "        scaler,\n",
    "        label_indexer,\n",
    "        rf_tune_model_instance\n",
    "    ])\n",
    "\n",
    "    # Definir la cuadrícula de parámetros a probar\n",
    "    rf_paramGrid = (ParamGridBuilder()\n",
    "                    .addGrid(rf_tune_model_instance.numTrees, [10, 50]) \n",
    "                    .addGrid(rf_tune_model_instance.maxDepth, [5, 10])  \n",
    "                    .addGrid(rf_tune_model_instance.minInstancesPerNode, [1, 5]) \n",
    "                    .build())\n",
    "\n",
    "    # Crear el CrossValidator\n",
    "    rf_crossval = CrossValidator(estimator=rf_tune_pipeline,\n",
    "                                 estimatorParamMaps=rf_paramGrid,\n",
    "                                 evaluator=MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"f1\"), # Usar F1 para seleccionar el mejor modelo\n",
    "                                 numFolds=3, # Número de folds para validación cruzada\n",
    "                                 seed=42,\n",
    "                                 parallelism=spark.sparkContext.defaultParallelism) # Usar todos los cores disponibles\n",
    "\n",
    "    # Entrenar el CrossValidator (puede tardar un tiempo considerable)\n",
    "    print(\"    Iniciando Cross-Validation para RandomForest... (Esto puede tomar tiempo)\")\n",
    "    rf_cv_model = rf_crossval.fit(tuning_data_df) # Entrenar en los datos de tuning\n",
    "    best_rf_pipeline_model = rf_cv_model.bestModel # El mejor pipeline entrenado\n",
    "\n",
    "    print(\"    Mejores Hiperparámetros encontrados para RandomForestClassifier:\")\n",
    "    best_rf_params = best_rf_pipeline_model.stages[-1].extractParamMap()\n",
    "    print(f\"      numTrees: {best_rf_params.get(rf_tune_model_instance.numTrees)}\")\n",
    "    print(f\"      maxDepth: {best_rf_params.get(rf_tune_model_instance.maxDepth)}\")\n",
    "    print(f\"      minInstancesPerNode: {best_rf_params.get(rf_tune_model_instance.minInstancesPerNode)}\")\n",
    "\n",
    "    # Puedes almacenar este `best_rf_pipeline_model` para usarlo en futuras inferencias o para re-evaluar las particiones.\n",
    "\n",
    "\n",
    "    # --- Ajuste de Hiperparámetros para KMeans ---\n",
    "    print(\"\\n  Ajustando Hiperparámetros para KMeans (k)...\")\n",
    "\n",
    "    # Instanciar un nuevo KMeans (sin k específico aquí)\n",
    "    kmeans_tune_model_instance = KMeans(featuresCol=\"scaled_features\", seed=42)\n",
    "\n",
    "    # Reconstruir el pipeline de KMeans para tuning\n",
    "    kmeans_tune_pipeline = Pipeline(stages=[\n",
    "        indexer_verified,\n",
    "        indexer_vine,\n",
    "        vector_assembler,\n",
    "        scaler,\n",
    "        kmeans_tune_model_instance\n",
    "    ])\n",
    "\n",
    "    # Definir la cuadrícula de parámetros para k\n",
    "    kmeans_paramGrid = (ParamGridBuilder()\n",
    "                        .addGrid(kmeans_tune_model_instance.k, [2, 3, 4, 5]) # Probar diferentes números de clústeres\n",
    "                        .build())\n",
    "\n",
    "    # Crear el CrossValidator\n",
    "    kmeans_crossval = CrossValidator(estimator=kmeans_tune_pipeline,\n",
    "                                     estimatorParamMaps=kmeans_paramGrid,\n",
    "                                     evaluator=ClusteringEvaluator(featuresCol=\"scaled_features\", metricName=\"silhouette\"), # Usar Silhouette para seleccionar el mejor k\n",
    "                                     numFolds=3, # Número de folds\n",
    "                                     seed=42,\n",
    "                                     parallelism=spark.sparkContext.defaultParallelism)\n",
    "\n",
    "    # Entrenar el CrossValidator\n",
    "    print(\"    Iniciando Cross-Validation para KMeans... (Esto puede tomar tiempo)\")\n",
    "    kmeans_cv_model = kmeans_crossval.fit(tuning_data_df) # Entrenar en los datos de tuning\n",
    "    best_kmeans_pipeline_model = kmeans_cv_model.bestModel # El mejor pipeline entrenado\n",
    "\n",
    "    print(\"    Mejor número de clústeres (k) encontrado para KMeans:\")\n",
    "    best_kmeans_k = best_kmeans_pipeline_model.stages[-1].getK()\n",
    "    print(f\"      k: {best_kmeans_k}\")\n",
    "\n",
    "    # Puedes almacenar este `best_kmeans_pipeline_model` para usarlo en futuras inferencias o análisis de clústeres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d88f71",
   "metadata": {},
   "source": [
    "## 4.4) Almacenamiento y carga de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5dc520",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"/ml_models/\"\n",
    "\n",
    "# Guardamos el mejor modelo RandomForest\n",
    "if 'best_rf_pipeline_model' in locals():\n",
    "    rf_model_save_path = path.join(base_model_path, \"random_forest_sentiment_classifier\")\n",
    "    best_rf_pipeline_model.write().overwrite().save(rf_model_save_path)\n",
    "    print(\"Modelo RandomForest guardado exitosamente.\")\n",
    "\n",
    "# Guardamos el mejor modelo KMeans\n",
    "if 'best_kmeans_pipeline_model' in locals():\n",
    "    kmeans_model_save_path = path.join(base_model_path, \"kmeans_review_clusters\")\n",
    "    best_kmeans_pipeline_model.write().overwrite().save(kmeans_model_save_path)\n",
    "    print(\"Modelo KMeans guardado exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c761b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "# Ejemplo de cómo cargar el modelo (RandomForestClassifier)\n",
    "loaded_rf_model = PipelineModel.load(rf_model_save_path)\n",
    "print(\"Modelo RandomForest cargado exitosamente\")\n",
    "\n",
    "# Ejemplo de cómo cargar el modelo (KMeans)\n",
    "loaded_kmeans_model = PipelineModel.load(kmeans_model_save_path)\n",
    "print(\"Modelo KMeans cargado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d9975c",
   "metadata": {},
   "source": [
    "# 5) Análisis de resultados\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd3a43c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
