{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto | lectura, escritura, archivos de Big Data PySpark - Implementación\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAESTRÍA EN INTELIGENCIA ARTIFICIAL APLICADA**\n",
    "\n",
    "**Curso: TC4034.10 - Análisis de grandes volúmenes de datos**\n",
    "\n",
    "Tecnológico de Monterrey\n",
    "\n",
    "* Dr. Iván Olmos Pineda\n",
    "* Mtra. Verónica Sandra Guzmán de Valle\n",
    "* Mtro. Alberto Daniel Salinas Montemayor\n",
    "\n",
    "**Proyecto**\n",
    "lectura, escritura, archivos de Big Data PySpark\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Equipo 37**\n",
    "\n",
    "|  NOMBRE COMPLETO                        |     MATRÍCULA     | \n",
    "| :-------------------------------------: |:-----------------:|\n",
    "| Alejandro Díaz Villagómez               |  A01276769        | \n",
    "| Alonso Pedrero Martínez                 |  A01769076        | \n",
    "| César Iván Pedrero Martínez             |  A01366501        | \n",
    "| Emiliano Saucedo Arriola                |  A01659258        | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del tema de interés\n",
    "--- \n",
    "\n",
    "El presente proyecto tiene como objetivo principal analizar las reseñas de productos publicadas en Amazon utilizando herramientas de Big Data, específicamente PySpark. Amazon, como empresa de reconocimiento mundial tanto en el ámbito del comercio electrónico como en el desarrollo de soluciones tecnológicas, destacando su plataforma AWS (Amazon Web Services), constituye un referente global en el sector. Además, su posicionamiento como líder indiscutible del mercado de marketplaces la convierte en una fuente valiosa de datos masivos para análisis de comportamiento del consumidor.\n",
    "\n",
    "La selección de este tema responde a intereses tanto profesionales como personales. Como programadores y consultores de software, frecuentemente trabajamos con clientes que solicitan el desarrollo de plataformas de venta en línea, mostrando un creciente interés en conocer la percepción y aceptación de sus productos en el mercado digital. En este contexto, resulta fundamental contar con herramientas que permitan identificar tendencias, analizar sentimientos y extraer patrones ocultos en las opiniones de los usuarios.\n",
    "\n",
    "Por tanto, el objetivo general de este proyecto es construir una solución que, a partir del procesamiento y análisis de grandes volúmenes de reseñas, permita:\n",
    "\n",
    "* Identificar el sentimiento general asociado a los productos (positivo, negativo o neutral).\n",
    "* Detectar tendencias y patrones recurrentes en las opiniones de los consumidores.\n",
    "* Apoyar en la toma de decisiones estratégicas de marketing y mejora de productos, proporcionando información valiosa y procesable a partir de los datos analizados.\n",
    "\n",
    "Este enfoque no solo fortalece nuestras competencias técnicas en Big Data (e incluso en temas como procesamiento de lenguaje natural - NLP), sino que también aporta una herramienta práctica y directamente aplicable a nuestro entorno laboral actual.\n",
    "\n",
    "\n",
    "Algunas aplicaciones potenciales son:\n",
    "\n",
    "* **Mejora de Productos**: Analizar las reseñas puede ayudar a identificar problemas recurrentes o aspectos destacados de los productos, ayudando a los fabricantes a mejorar los diseños o la experiencia del cliente.\n",
    "* **Atención al Cliente y Soporte**: Identificar rápidamente las reseñas negativas permite a las empresas abordar las preocupaciones de los clientes de manera eficiente, mejorando la satisfacción del cliente.\n",
    "* **Sistemas de Recomendación**: El conjunto de datos puede usarse para mejorar los sistemas de recomendación, correlacionando las calificaciones de los productos, los sentimientos y las preferencias de los clientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección del dataset\n",
    "---\n",
    "\n",
    "### **Selección**\n",
    "\n",
    "| **Campo**              | **Detalle**                                                                                  |\n",
    "|-------------------------|----------------------------------------------------------------------------------------------|\n",
    "| Nombre del dataset      | Amazon-reviews                                                                               |\n",
    "| Enlace                  | [Amazon-reviews en Kaggle](https://www.kaggle.com/datasets/machharavikiran/amazon-reviews?resource=download) |\n",
    "| Publicador              | Machha Ravi Kiran                                                                            |\n",
    "| Última actualización    | Hace aproximadamente 2 años                                                                  |\n",
    "| Formato - Tamaño        | CSV - 3.68 GB                                                                                 |\n",
    "| Fuente                  | Repositorio Kaggle (acceso público)                                                           |\n",
    "\n",
    "---\n",
    "\n",
    "### **Atributos del Conjunto de Datos**\n",
    "\n",
    "| Columna           | Tipo de dato | Descripción                                      |\n",
    "|-------------------|--------------|--------------------------------------------------|\n",
    "| marketplace       | string       | Mercado donde se realizó la compra               |\n",
    "| customer_id       | integer      | Identificador único del cliente                        |\n",
    "| review_id         | string       | Identificador único de la reseña                 |\n",
    "| product_id        | string       | Identificador del producto                      |\n",
    "| product_parent    | integer      | Identificador de grupo o \"padre\" para productos similares o relacionados             |\n",
    "| product_title     | string       | Nombre del producto                              |\n",
    "| product_category  | string       | Categoría del producto                           |\n",
    "| star_rating       | integer      | Calificación otorgada por el cliente (1-5)             |\n",
    "| helpful_votes     | integer      | Número de votos útiles recibidos por la reseña    |\n",
    "| total_votes       | integer      | Número total de votos recibidos                  |\n",
    "| vine              | string       | Participación en el programa Vine de reseñas (Y para sí, N para no)    |\n",
    "| verified_purchase | string       | Indicador de compra verificada (Y para sí, N para no)                  |\n",
    "| review_headline   | string       | Encabezado de la reseña                          |\n",
    "| review_body       | string       | Cuerpo del texto de la reseña                    |\n",
    "| review_date       | date         | Fecha en que se realizó la reseña                |\n",
    "| sentiment         | integer      | Valor de sentimiento asignado a la reseña (1 para positivo, 0 para negativo)       |\n",
    "\n",
    "---\n",
    "\n",
    "### **Descripción General**\n",
    "\n",
    "Este conjunto de datos contiene reseñas de productos publicadas en Amazon, con un enfoque principal en productos electrónicos. La información es detallada, incluyendo las calificaciones de los usuarios, comentarios, votos útiles, y otros aspectos que permiten realizar un análisis profundo del comportamiento del consumidor y el sentimiento de las reseñas.\n",
    "\n",
    "El dataset seleccionado cumple con los criterios establecidos para este proyecto, ya que está directamente relacionado con el análisis de reseñas de productos, presenta un tamaño adecuado para técnicas de Big Data, y su formato tabular favorece su procesamiento mediante PySpark. Además, la procedencia del dataset, proveniente de una fuente reconocida como Kaggle, garantiza además su calidad y fiabilidad para los fines académicos y profesionales de este trabajo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis con PySpark\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that to run this notebook, you'll need to install some dependencies. It's HIGHLY suggested to run this command to actually install it in a virtual environment by following this command:\n",
    "\n",
    "`python3 -m venv venv && source venv/bin/activate && pip install findspark pyspark matplotlib seaborn setuptools kagglehub`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, isnan, when, count, lit\n",
    "from pyspark.sql.types import StringType, IntegerType, LongType, DoubleType, FloatType, DecimalType, ShortType, NumericType\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializar Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/emisaar/anaconda3/envs/pyspark_env/lib/python3.10/site-packages/pyspark'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.100.73:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x15a536170>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/emisaar/.cache/kagglehub/datasets/machharavikiran/amazon-reviews/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "FILE_PATH = kagglehub.dataset_download(\"machharavikiran/amazon-reviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileManager():\n",
    "    @staticmethod\n",
    "    def open_csv_file(file_path: str):\n",
    "        \"\"\"\n",
    "        This method opens a csv file with pyspark\n",
    "        \"\"\"\n",
    "        csv_df = spark.read.csv(\n",
    "            file_path,\n",
    "            header=True,\n",
    "            inferSchema=True,\n",
    "            multiLine=True,\n",
    "            escape=\"\\\"\",\n",
    "            quote=\"\\\"\"\n",
    "        )\n",
    "\n",
    "        # csv_df.show(truncate=20)\n",
    "\n",
    "        return csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatisticalAnalysisHelper():\n",
    "    @staticmethod\n",
    "    def dataset_dimensions(df_input):\n",
    "        print(\"columns in the dataset:\", len(df_input.columns))\n",
    "        print(\"rows in the dataset:\", df_input.count())\n",
    "\n",
    "    @staticmethod\n",
    "    def schema_information(df_input):\n",
    "        \"\"\"\n",
    "        This method shows the current schema of the data.\n",
    "        \"\"\"\n",
    "        df_input.printSchema()\n",
    "\n",
    "    @staticmethod\n",
    "    def descriptive_statistics(df_input, variable_type=\"numeric\"):\n",
    "        \"\"\"\n",
    "        Shows descriptive statistics for the dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - df_input: Spark DataFrame\n",
    "        - variable_type: 'numeric' to show numeric columns, 'non-numeric' to show others\n",
    "        \"\"\"\n",
    "        numeric_cols = [field.name for field in df_input.schema.fields if isinstance(field.dataType, NumericType)]\n",
    "        non_numeric_cols = [field.name for field in df_input.schema.fields if field.name not in numeric_cols]\n",
    "\n",
    "        if variable_type == \"numeric\":\n",
    "            print(\"\\n=== Numeric Variables ===\")\n",
    "            if numeric_cols:\n",
    "                display(df_input.select(numeric_cols).summary().toPandas())\n",
    "            else:\n",
    "                print(\"No numeric columns found.\")\n",
    "        \n",
    "        elif variable_type == \"non-numeric\":\n",
    "            print(\"\\n=== Non-numeric Variables ===\")\n",
    "            if non_numeric_cols:\n",
    "                for col_name in non_numeric_cols:\n",
    "                    print(f\"Columna: {col_name}\")\n",
    "                    print(\"--\" * 20)\n",
    "                    display(df_input.groupBy(col(col_name)).count().orderBy(\"count\", ascending=False).limit(5).toPandas())\n",
    "            else:\n",
    "                print(\"No non-numeric columns found.\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"Invalid variable_type: {variable_type}. Choose 'numeric' or 'non-numeric'.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def missing_values_table(df_input):\n",
    "        \"\"\"\n",
    "        Displays a table with the count of missing values per column.\n",
    "        \"\"\"\n",
    "        missing_exprs = []\n",
    "        \n",
    "        for c in df_input.schema.fields:\n",
    "            field_name = c.name\n",
    "            field_type = c.dataType\n",
    "            \n",
    "            if isinstance(field_type, (IntegerType, LongType, DoubleType, FloatType, DecimalType, ShortType, NumericType)):\n",
    "                missing_exprs.append(\n",
    "                    count(when(col(field_name).isNull() | isnan(col(field_name)), field_name)).alias(field_name)\n",
    "                )\n",
    "            elif isinstance(field_type, StringType):\n",
    "                missing_exprs.append(\n",
    "                    count(when(col(field_name).isNull() | (col(field_name) == \"\"), field_name)).alias(field_name)\n",
    "                )\n",
    "            else:\n",
    "                missing_exprs.append(\n",
    "                    count(when(col(field_name).isNull(), field_name)).alias(field_name)\n",
    "                )\n",
    "\n",
    "        df_missing_values = df_input.select(missing_exprs)\n",
    "\n",
    "        return df_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualAnalysisHelper:\n",
    "    @staticmethod\n",
    "    def missing_values_plot(df_missing_values):\n",
    "        \"\"\"\n",
    "        This method shows the missing values and plots them.\n",
    "        \"\"\"\n",
    "        df_missing_values_pd = df_missing_values.toPandas()\n",
    "\n",
    "        df_missing_values_pd = df_missing_values_pd.melt(var_name=\"column\", value_name=\"missing_count\")\n",
    "\n",
    "        plt.figure(figsize=(10,6))\n",
    "        sns.barplot(x=\"column\", y=\"missing_count\", data=df_missing_values_pd)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.title(\"Missing Values per Column\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def column_distribution_plot(df_input, column_name, x_label, y_label):\n",
    "        \"\"\"\n",
    "        This method plots the distribution of the 'star_rating' column.\n",
    "        \"\"\"\n",
    "\n",
    "        rating_counts = (\n",
    "            df_input.groupBy(column_name)\n",
    "            .count()\n",
    "            .orderBy(column_name)\n",
    "        )\n",
    "\n",
    "        plot_data = rating_counts.toPandas()\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.barplot(x=column_name, y=\"count\", data=plot_data)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "        plt.title(\"Distribution of Values\")\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>22873041</td>\n",
       "      <td>R3ARRMDEGED8RD</td>\n",
       "      <td>B00KJWQIIC</td>\n",
       "      <td>335625766</td>\n",
       "      <td>Plemo 14-Inch Laptop Sleeve Case Waterproof Fa...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Pleasantly surprised</td>\n",
       "      <td>I was very surprised at the high quality of th...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>30088427</td>\n",
       "      <td>RQ28TSA020Y6J</td>\n",
       "      <td>B013ALA9LA</td>\n",
       "      <td>671157305</td>\n",
       "      <td>TP-Link OnHub AC1900 Wireless Wi-Fi Router</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>OnHub is a pretty no nonsense type router that...</td>\n",
       "      <td>I am a Google employee and had to chance to us...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>20329786</td>\n",
       "      <td>RUXJRZCT6953M</td>\n",
       "      <td>B00PML2GQ8</td>\n",
       "      <td>982036237</td>\n",
       "      <td>AmazonBasics USB 3.0 A Male to A Male Cable - ...</td>\n",
       "      <td>PC</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>None of them worked.  No functionality at all.</td>\n",
       "      <td>Bought cables in 3ft, 6ft and 9ft.  NONE of th...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>14215710</td>\n",
       "      <td>R7EO0UO6BPB71</td>\n",
       "      <td>B001NS0OZ4</td>\n",
       "      <td>576587596</td>\n",
       "      <td>Transcend P8 15-in-1 USB 2.0 Flash Memory Card...</td>\n",
       "      <td>PC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>just keep searching.</td>\n",
       "      <td>nope, cheap and slow</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>38264512</td>\n",
       "      <td>R39NJY2YJ1JFSV</td>\n",
       "      <td>B00AQMTND2</td>\n",
       "      <td>964759214</td>\n",
       "      <td>Aleratec SATA Data Cable 2.0 20in Serial ATA S...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Excellent! Great value and does the job.</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US</td>\n",
       "      <td>30548466</td>\n",
       "      <td>R31SR7REWNX7CF</td>\n",
       "      <td>B00KX4TORI</td>\n",
       "      <td>170101802</td>\n",
       "      <td>Kingston Digital MobileLite G4 USB 3.0 Multi-F...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Good quality, works well and compact</td>\n",
       "      <td>Good quality,works well and compact size</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>US</td>\n",
       "      <td>589298</td>\n",
       "      <td>RVBP8I1R0CTZ8</td>\n",
       "      <td>B00P17WEMY</td>\n",
       "      <td>206124740</td>\n",
       "      <td>White 9 Inch Unlocked Dual Sim Card Phone Tabl...</td>\n",
       "      <td>PC</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>in fact this is third China good. Demn s***</td>\n",
       "      <td>This demn tablet is just a Real Chinese produc...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>US</td>\n",
       "      <td>49329488</td>\n",
       "      <td>R1QF6RS1PDLU18</td>\n",
       "      <td>B00TR05L9Y</td>\n",
       "      <td>778403103</td>\n",
       "      <td>Lenovo TAB2 A10 - 10.1\" 2-in-1 Tablet (1.5Ghz,...</td>\n",
       "      <td>PC</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Good</td>\n",
       "      <td>I am not sure I don't know if it is the tablet...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>US</td>\n",
       "      <td>50728290</td>\n",
       "      <td>R23AICGEDAJQL1</td>\n",
       "      <td>B0098Y77OG</td>\n",
       "      <td>177098042</td>\n",
       "      <td>Acer</td>\n",
       "      <td>PC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>You get what you pay for</td>\n",
       "      <td>After exactly 45 days, the screen went dark. P...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>US</td>\n",
       "      <td>37802374</td>\n",
       "      <td>R2EY3N4K9W19UP</td>\n",
       "      <td>B00IFYEYXC</td>\n",
       "      <td>602496520</td>\n",
       "      <td>AzureWave Broadcom BCM94352HMB 802.11/ac/867Mb...</td>\n",
       "      <td>PC</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great for Windows 7 Laptop!</td>\n",
       "      <td>Replaced my Intel Centrino 2230 with the BCM94...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     22873041  R3ARRMDEGED8RD  B00KJWQIIC       335625766   \n",
       "1          US     30088427   RQ28TSA020Y6J  B013ALA9LA       671157305   \n",
       "2          US     20329786   RUXJRZCT6953M  B00PML2GQ8       982036237   \n",
       "3          US     14215710   R7EO0UO6BPB71  B001NS0OZ4       576587596   \n",
       "4          US     38264512  R39NJY2YJ1JFSV  B00AQMTND2       964759214   \n",
       "5          US     30548466  R31SR7REWNX7CF  B00KX4TORI       170101802   \n",
       "6          US       589298   RVBP8I1R0CTZ8  B00P17WEMY       206124740   \n",
       "7          US     49329488  R1QF6RS1PDLU18  B00TR05L9Y       778403103   \n",
       "8          US     50728290  R23AICGEDAJQL1  B0098Y77OG       177098042   \n",
       "9          US     37802374  R2EY3N4K9W19UP  B00IFYEYXC       602496520   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  Plemo 14-Inch Laptop Sleeve Case Waterproof Fa...               PC   \n",
       "1         TP-Link OnHub AC1900 Wireless Wi-Fi Router               PC   \n",
       "2  AmazonBasics USB 3.0 A Male to A Male Cable - ...               PC   \n",
       "3  Transcend P8 15-in-1 USB 2.0 Flash Memory Card...               PC   \n",
       "4  Aleratec SATA Data Cable 2.0 20in Serial ATA S...               PC   \n",
       "5  Kingston Digital MobileLite G4 USB 3.0 Multi-F...               PC   \n",
       "6  White 9 Inch Unlocked Dual Sim Card Phone Tabl...               PC   \n",
       "7  Lenovo TAB2 A10 - 10.1\" 2-in-1 Tablet (1.5Ghz,...               PC   \n",
       "8                                               Acer               PC   \n",
       "9  AzureWave Broadcom BCM94352HMB 802.11/ac/867Mb...               PC   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              0            0    N                 Y   \n",
       "1            5             24           31    N                 N   \n",
       "2            1              2            2    N                 N   \n",
       "3            1              0            0    N                 Y   \n",
       "4            5              0            0    N                 Y   \n",
       "5            5              0            0    N                 Y   \n",
       "6            3              1            2    N                 Y   \n",
       "7            4              1            1    N                 Y   \n",
       "8            1              0            0    N                 Y   \n",
       "9            5              3            4    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                               Pleasantly surprised   \n",
       "1  OnHub is a pretty no nonsense type router that...   \n",
       "2     None of them worked.  No functionality at all.   \n",
       "3                               just keep searching.   \n",
       "4                                         Five Stars   \n",
       "5               Good quality, works well and compact   \n",
       "6        in fact this is third China good. Demn s***   \n",
       "7                                               Good   \n",
       "8                           You get what you pay for   \n",
       "9                        Great for Windows 7 Laptop!   \n",
       "\n",
       "                                         review_body review_date  sentiment  \n",
       "0  I was very surprised at the high quality of th...  2015-08-31          1  \n",
       "1  I am a Google employee and had to chance to us...  2015-08-31          1  \n",
       "2  Bought cables in 3ft, 6ft and 9ft.  NONE of th...  2015-08-31          0  \n",
       "3                               nope, cheap and slow  2015-08-31          0  \n",
       "4           Excellent! Great value and does the job.  2015-08-31          1  \n",
       "5           Good quality,works well and compact size  2015-08-31          1  \n",
       "6  This demn tablet is just a Real Chinese produc...  2015-08-31          0  \n",
       "7  I am not sure I don't know if it is the tablet...  2015-08-31          1  \n",
       "8  After exactly 45 days, the screen went dark. P...  2015-08-31          0  \n",
       "9  Replaced my Intel Centrino 2230 with the BCM94...  2015-08-31          1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = FileManager.open_csv_file(FILE_PATH)\n",
    "df_reviews.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_star = df_reviews\n",
    "\n",
    "# Conteo por estrella\n",
    "star_rating_counts = df_star.groupBy(\"star_rating\").count().orderBy(\"star_rating\")\n",
    "\n",
    "# Estadísticas de star_rating\n",
    "star_rating_stats = df_star.agg(\n",
    "    F.min(\"star_rating\"), F.max(\"star_rating\"),\n",
    "    F.avg(\"star_rating\"), F.stddev(\"star_rating\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+-------------------+---------------------+\n",
      "|min(helpful_ratio)|max(helpful_ratio)| avg(helpful_ratio)|stddev(helpful_ratio)|\n",
      "+------------------+------------------+-------------------+---------------------+\n",
      "|               0.0|               1.0|0.23128070845636955|   0.3967627166047604|\n",
      "+------------------+------------------+-------------------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_with_ratio = df_star.withColumn(\n",
    "    \"helpful_ratio\", \n",
    "    F.when(F.col(\"total_votes\") > 0, F.col(\"helpful_votes\") / F.col(\"total_votes\")).otherwise(0)\n",
    ")\n",
    "\n",
    "helpful_ratio_stats = df_with_ratio.agg(\n",
    "    F.min(\"helpful_ratio\"), F.max(\"helpful_ratio\"),\n",
    "    F.avg(\"helpful_ratio\"), F.stddev(\"helpful_ratio\")\n",
    ")\n",
    "helpful_ratio_stats.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+------------------+-------------------+\n",
      "|min(total_votes)|max(total_votes)|  avg(total_votes)|stddev(total_votes)|\n",
      "+----------------+----------------+------------------+-------------------+\n",
      "|               0|           48362|1.9620770907212328|  43.07079218821245|\n",
      "+----------------+----------------+------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "total_votes_stats = df_with_ratio.agg(\n",
    "    F.min(\"total_votes\"), F.max(\"total_votes\"),\n",
    "    F.avg(\"total_votes\"), F.stddev(\"total_votes\")\n",
    ")\n",
    "total_votes_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|sentiment|  count|\n",
      "+---------+-------+\n",
      "|        0|1632669|\n",
      "|        1|5273895|\n",
      "+---------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|proporcion_positiva|\n",
      "+-------------------+\n",
      "| 0.7636061868101128|\n",
      "+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sentiment_counts = df_with_ratio.groupBy(\"sentiment\").count().orderBy(\"sentiment\")\n",
    "sentiment_stats = df_with_ratio.agg(F.avg(\"sentiment\").alias(\"proporcion_positiva\"))\n",
    "sentiment_counts.show()\n",
    "sentiment_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|   17957446|  458|\n",
      "|   44834233|  442|\n",
      "|   52938899|  366|\n",
      "|   45664110|  275|\n",
      "|   49452274|  261|\n",
      "|   50820654|  256|\n",
      "|   12200139|  251|\n",
      "|   45070473|  251|\n",
      "|   32038204|  241|\n",
      "|   49266466|  240|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "customer_top10 = df_with_ratio.groupBy(\"customer_id\").count().orderBy(F.desc(\"count\")).limit(10)\n",
    "customer_top10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------+\n",
      "|vine|  count|proportion|\n",
      "+----+-------+----------+\n",
      "|   Y|  36228|    0.0052|\n",
      "|   N|6870336|    0.9948|\n",
      "+----+-------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "vine_counts = df_with_ratio.groupBy(\"vine\").count()\n",
    "total_reviews = df_with_ratio.count()\n",
    "\n",
    "vine_proportions = vine_counts.withColumn(\n",
    "    \"proportion\", F.round(F.col(\"count\") / F.lit(total_reviews), 4)\n",
    ")\n",
    "vine_proportions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+----------+\n",
      "|verified_purchase|  count|proportion|\n",
      "+-----------------+-------+----------+\n",
      "|                Y|6047075|    0.8756|\n",
      "|                N| 859489|    0.1244|\n",
      "+-----------------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "verified_counts = df_with_ratio.groupBy(\"verified_purchase\").count()\n",
    "\n",
    "verified_proportions = verified_counts.withColumn(\n",
    "    \"proportion\", F.round(F.col(\"count\") / F.lit(total_reviews), 4)\n",
    ")\n",
    "verified_proportions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|review_year|  count|\n",
      "+-----------+-------+\n",
      "|       1999|    384|\n",
      "|       2000|   3596|\n",
      "|       2001|   6588|\n",
      "|       2002|  10125|\n",
      "|       2003|  13619|\n",
      "|       2004|  14124|\n",
      "|       2005|  18171|\n",
      "|       2006|  26277|\n",
      "|       2007|  59870|\n",
      "|       2008|  81409|\n",
      "|       2009| 129840|\n",
      "|       2010| 213170|\n",
      "|       2011| 397182|\n",
      "|       2012| 661742|\n",
      "|       2013|1396819|\n",
      "|       2014|1996666|\n",
      "|       2015|1876982|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_with_year = df_with_ratio.withColumn(\"review_year\", F.year(\"review_date\"))\n",
    "reviews_by_year = df_with_year.groupBy(\"review_year\").count().orderBy(\"review_year\")\n",
    "reviews_by_year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+----------+\n",
      "|product_category|count  |proporcion|\n",
      "+----------------+-------+----------+\n",
      "|PC              |6906564|1.0       |\n",
      "+----------------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+----------+\n",
      "|verified_purchase|  count|proporcion|\n",
      "+-----------------+-------+----------+\n",
      "|                Y|6047075|    0.8756|\n",
      "|                N| 859489|    0.1244|\n",
      "+-----------------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, round\n",
    "\n",
    "# Total de registros para calcular proporciones\n",
    "total = df_reviews.count()\n",
    "\n",
    "# === Caracterización de product_category ===\n",
    "carac_categoria = (\n",
    "    df_reviews.groupBy(\"product_category\")\n",
    "    .count()\n",
    "    .withColumn(\"proporcion\", round(col(\"count\") / total, 4))\n",
    "    .orderBy(col(\"count\").desc())\n",
    ")\n",
    "carac_categoria.show(truncate=False)\n",
    "\n",
    "# === Caracterización de verified_purchase ===\n",
    "carac_verificado = (\n",
    "    df_reviews.groupBy(\"verified_purchase\")\n",
    "    .count()\n",
    "    .withColumn(\"proporcion\", round(col(\"count\") / total, 4))\n",
    "    .orderBy(col(\"count\").desc())\n",
    ")\n",
    "carac_verificado.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+\n",
      "|marketplace|  count|proporcion|\n",
      "+-----------+-------+----------+\n",
      "|         US|6906564|       1.0|\n",
      "+-----------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "carac_marketplace = (\n",
    "    df_reviews.groupBy(\"marketplace\")\n",
    "    .count()\n",
    "    .withColumn(\"proporcion\", round(col(\"count\") / total, 4))\n",
    "    .orderBy(col(\"marketplace\"))\n",
    ")\n",
    "carac_marketplace.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+\n",
      "|star_rating|count  |proporcion|\n",
      "+-----------+-------+----------+\n",
      "|1          |756857 |0.1096    |\n",
      "|2          |362156 |0.0524    |\n",
      "|3          |513656 |0.0744    |\n",
      "|4          |1168208|0.1691    |\n",
      "|5          |4105687|0.5945    |\n",
      "+-----------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+----------+\n",
      "|sentiment|  count|proporcion|\n",
      "+---------+-------+----------+\n",
      "|        0|1632669|    0.2364|\n",
      "|        1|5273895|    0.7636|\n",
      "+---------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, round\n",
    "\n",
    "# Total de registros para calcular proporciones\n",
    "total = df_reviews.count()\n",
    "\n",
    "# === Caracterización de product_category ===\n",
    "carac_star = (\n",
    "    df_reviews.groupBy(\"star_rating\")\n",
    "    .count()\n",
    "    .withColumn(\"proporcion\", round(col(\"count\") / total, 4))\n",
    "    .orderBy(col(\"star_rating\"))\n",
    ")\n",
    "carac_star.show(truncate=False)\n",
    "\n",
    "# === Caracterización de sentiment ===\n",
    "carac_sentiment = (\n",
    "    df_reviews.groupBy(\"sentiment\")\n",
    "    .count()\n",
    "    .withColumn(\"proporcion\", round(col(\"count\") / total, 4))\n",
    "    .orderBy(col(\"sentiment\"))\n",
    ")\n",
    "carac_sentiment.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------+----------+\n",
      "|star_rating|sentiment|count  |proporcion|\n",
      "+-----------+---------+-------+----------+\n",
      "|1          |0        |756857 |0.1096    |\n",
      "|2          |0        |362156 |0.0524    |\n",
      "|3          |0        |513656 |0.0744    |\n",
      "|4          |1        |1168208|0.1691    |\n",
      "|5          |1        |4105687|0.5945    |\n",
      "+-----------+---------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, round\n",
    "\n",
    "# === Calcular total de registros ===\n",
    "total = df_reviews.count()\n",
    "\n",
    "# === Agrupar por combinaciones de star_rating y sentiment ===\n",
    "combinaciones = (\n",
    "    df_reviews.groupBy(\"star_rating\", \"sentiment\")\n",
    "    .count()\n",
    "    .withColumn(\"proporcion\", round(col(\"count\") / total, 4))\n",
    "    .orderBy(col(\"star_rating\").asc(), col(\"sentiment\").desc())\n",
    ")\n",
    "\n",
    "# === Mostrar combinaciones con probabilidad ===\n",
    "combinaciones.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entonces, combinar sentiment y star_rating no aporta mucha variedad para el particionamiento (porque una variable se infiere de la otra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+-------+----------+\n",
      "|star_rating|verified_purchase|count  |proporcion|\n",
      "+-----------+-----------------+-------+----------+\n",
      "|1          |Y                |603373 |0.0874    |\n",
      "|1          |N                |153484 |0.0222    |\n",
      "|2          |Y                |300549 |0.0435    |\n",
      "|2          |N                |61607  |0.0089    |\n",
      "|3          |Y                |443372 |0.0642    |\n",
      "|3          |N                |70284  |0.0102    |\n",
      "|4          |Y                |1019771|0.1477    |\n",
      "|4          |N                |148437 |0.0215    |\n",
      "|5          |Y                |3680010|0.5328    |\n",
      "|5          |N                |425677 |0.0616    |\n",
      "+-----------+-----------------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, round\n",
    "\n",
    "# === Calcular total de registros ===\n",
    "total = df_reviews.count()\n",
    "\n",
    "# === Agrupar por combinaciones de star_rating y verified_purchase ===\n",
    "combinaciones_rating_verificado = (\n",
    "    df_reviews.groupBy(\"star_rating\", \"verified_purchase\")\n",
    "    .count()\n",
    "    .withColumn(\"proporcion\", round(col(\"count\") / total, 4))\n",
    "    .orderBy(col(\"star_rating\").asc(), col(\"verified_purchase\").desc())\n",
    ")\n",
    "\n",
    "# === Mostrar resultados ===\n",
    "combinaciones_rating_verificado.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las estadísticas descriptivas de las variables numéricas indican que el dataset está concentrado en calificaciones altas (`star_rating` promedio de 4.08) y en sentimientos mayoritariamente positivos (`sentiment` promedio de 0.76). La mayoría de los productos recibieron pocos votos útiles y totales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
